{
  "junayedahmedd-gemini-cli-skill": {
    "id": "junayedahmedd-gemini-cli-skill",
    "name": "gemini-cli",
    "description": "Wield Google's Gemini CLI as a powerful auxiliary tool for code generation, review, analysis, and web research. Use when tasks benefit from a second AI perspective, current web information via Google Search, codebase architecture analysis, or parallel code generation. Also use when user explicitly requests Gemini operations.",
    "repo": {
      "owner": "Junayedahmedd",
      "name": "gemini_cli_skill",
      "fullName": "Junayedahmedd/gemini_cli_skill",
      "url": "https://github.com/Junayedahmedd/gemini_cli_skill",
      "defaultBranch": "main"
    },
    "metadata": {
      "stars": 2,
      "forks": 0,
      "language": null,
      "topics": [
        "ai-agent",
        "ai-tools",
        "anthropic",
        "caching",
        "claude-code",
        "claude-skills",
        "claude-skills-creator",
        "codex",
        "codex-cli",
        "gemini",
        "gemini-cli",
        "korean-law",
        "llama",
        "openai",
        "qwen",
        "search-plugin",
        "skills",
        "web-search"
      ],
      "createdAt": "2024-09-29T19:36:56Z",
      "updatedAt": "2026-01-07T23:15:48Z",
      "pushedAt": "2026-01-07T23:15:45Z"
    },
    "category": "tools",
    "tags": [
      "ai-agent",
      "ai-tools",
      "anthropic",
      "caching",
      "claude-code",
      "claude-skills",
      "claude-skills-creator",
      "codex",
      "codex-cli",
      "gemini"
    ],
    "skillMd": {
      "raw": "---\nname: gemini-cli\ndescription: Wield Google's Gemini CLI as a powerful auxiliary tool for code generation, review, analysis, and web research. Use when tasks benefit from a second AI perspective, current web information via Google Search, codebase architecture analysis, or parallel code generation. Also use when user explicitly requests Gemini operations.\nallowed-tools:\n  - Bash\n  - Read\n  - Write\n  - Grep\n  - Glob\n---\n\n# Gemini CLI Integration Skill\n\nThis skill enables Claude Code to effectively orchestrate Gemini CLI (v0.16.0+) with Gemini 3 Pro for code generation, review, analysis, and specialized tasks.\n\n## When to Use This Skill\n\n### Ideal Use Cases\n\n1. **Second Opinion / Cross-Validation**\n   - Code review after writing code (different AI perspective)\n   - Security audit with alternative analysis\n   - Finding bugs Claude might have missed\n\n2. **Google Search Grounding**\n   - Questions requiring current internet information\n   - Latest library versions, API changes, documentation updates\n   - Current events or recent releases\n\n3. **Codebase Architecture Analysis**\n   - Use Gemini's `codebase_investigator` tool\n   - Understanding unfamiliar codebases\n   - Mapping cross-file dependencies\n\n4. **Parallel Processing**\n   - Offload tasks while continuing other work\n   - Run multiple code generations simultaneously\n   - Background documentation generation\n\n5. **Specialized Generation**\n   - Test suite generation\n   - JSDoc/documentation generation\n   - Code translation between languages\n\n### When NOT to Use\n\n- Simple, quick tasks (overhead not worth it)\n- Tasks requiring immediate response (rate limits cause delays)\n- When context is already loaded and understood\n- Interactive refinement requiring conversation\n\n## Core Instructions\n\n### 1. Verify Installation\n\n```bash\ncommand -v gemini || which gemini\n```\n\n### 2. Basic Command Pattern\n\n```bash\ngemini \"[prompt]\" --yolo -o text 2>&1\n```\n\nKey flags:\n- `--yolo` or `-y`: Auto-approve all tool calls\n- `-o text`: Human-readable output\n- `-o json`: Structured output with stats\n- `-m gemini-2.5-flash`: Use faster model for simple tasks\n\n### 3. Critical Behavioral Notes\n\n**YOLO Mode Behavior**: Auto-approves tool calls but does NOT prevent planning prompts. Gemini may still present plans and ask \"Does this plan look good?\" Use forceful language:\n- \"Apply now\"\n- \"Start immediately\"\n- \"Do this without asking for confirmation\"\n\n**Rate Limits**: Free tier has 60 requests/min, 1000/day. CLI auto-retries with backoff. Expect messages like \"quota will reset after Xs\".\n\n### 4. Output Processing\n\nFor JSON output (`-o json`), parse:\n```json\n{\n  \"response\": \"actual content\",\n  \"stats\": {\n    \"models\": { \"tokens\": {...} },\n    \"tools\": { \"byName\": {...} }\n  }\n}\n```\n\n## Quick Reference Commands\n\n### Code Generation\n```bash\ngemini \"Create [description] with [features]. Output complete file content.\" --yolo -o text\n```\n\n### Code Review\n```bash\ngemini \"Review [file] for: 1) features, 2) bugs/security issues, 3) improvements\" -o text\n```\n\n### Bug Fixing\n```bash\ngemini \"Fix these bugs in [file]: [list]. Apply fixes now.\" --yolo -o text\n```\n\n### Test Generation\n```bash\ngemini \"Generate [Jest/pytest] tests for [file]. Focus on [areas].\" --yolo -o text\n```\n\n### Documentation\n```bash\ngemini \"Generate JSDoc for all functions in [file]. Output as markdown.\" --yolo -o text\n```\n\n### Architecture Analysis\n```bash\ngemini \"Use codebase_investigator to analyze this project\" -o text\n```\n\n### Web Research\n```bash\ngemini \"What are the latest [topic]? Use Google Search.\" -o text\n```\n\n### Faster Model (Simple Tasks)\n```bash\ngemini \"[prompt]\" -m gemini-2.5-flash -o text\n```\n\n## Error Handling\n\n### Rate Limit Exceeded\n- CLI auto-retries with backoff\n- Use `-m gemini-2.5-flash` for lower priority tasks\n- Run in background for long operations\n\n### Command Failures\n- Check JSON output for detailed error stats\n- Verify Gemini is authenticated: `gemini --version`\n- Check `~/.gemini/settings.json` for config issues\n\n### Validation After Generation\nAlways verify Gemini's output:\n- Check for security vulnerabilities (XSS, injection)\n- Test functionality matches requirements\n- Review code style consistency\n- Verify dependencies are appropriate\n\n## Integration Workflow\n\n### Standard Generate-Review-Fix Cycle\n\n```bash\n# 1. Generate\ngemini \"Create [code]\" --yolo -o text\n\n# 2. Review (Gemini reviews its own work)\ngemini \"Review [file] for bugs and security issues\" -o text\n\n# 3. Fix identified issues\ngemini \"Fix [issues] in [file]. Apply now.\" --yolo -o text\n```\n\n### Background Execution\n\nFor long tasks, run in background and monitor:\n```bash\ngemini \"[long task]\" --yolo -o text 2>&1 &\n# Monitor with BashOutput tool\n```\n\n## Gemini's Unique Capabilities\n\nThese tools are available only through Gemini:\n\n1. **google_web_search** - Real-time internet search via Google\n2. **codebase_investigator** - Deep architectural analysis\n3. **save_memory** - Cross-session persistent memory\n\n## Configuration\n\n### Project Context (Optional)\n\nCreate `.gemini/GEMINI.md` in project root for persistent context that Gemini will automatically read.\n\n### Session Management\n\nList sessions: `gemini --list-sessions`\nResume session: `echo \"follow-up\" | gemini -r [index] -o text`\n\n## See Also\n\n- `reference.md` - Complete command and flag reference\n- `templates.md` - Prompt templates for common operations\n- `patterns.md` - Advanced integration patterns\n- `tools.md` - Gemini's built-in tools documentation\n",
      "frontmatter": {
        "name": "gemini-cli",
        "description": "Wield Google's Gemini CLI as a powerful auxiliary tool for code generation, review, analysis, and web research. Use when tasks benefit from a second AI perspective, current web information via Google Search, codebase architecture analysis, or parallel code generation. Also use when user explicitly requests Gemini operations.",
        "allowed-tools": [
          "Bash",
          "Read",
          "Write",
          "Grep",
          "Glob"
        ]
      },
      "content": "# Gemini CLI Integration Skill\n\nThis skill enables Claude Code to effectively orchestrate Gemini CLI (v0.16.0+) with Gemini 3 Pro for code generation, review, analysis, and specialized tasks.\n\n## When to Use This Skill\n\n### Ideal Use Cases\n\n1. **Second Opinion / Cross-Validation**\n   - Code review after writing code (different AI perspective)\n   - Security audit with alternative analysis\n   - Finding bugs Claude might have missed\n\n2. **Google Search Grounding**\n   - Questions requiring current internet information\n   - Latest library versions, API changes, documentation updates\n   - Current events or recent releases\n\n3. **Codebase Architecture Analysis**\n   - Use Gemini's `codebase_investigator` tool\n   - Understanding unfamiliar codebases\n   - Mapping cross-file dependencies\n\n4. **Parallel Processing**\n   - Offload tasks while continuing other work\n   - Run multiple code generations simultaneously\n   - Background documentation generation\n\n5. **Specialized Generation**\n   - Test suite generation\n   - JSDoc/documentation generation\n   - Code translation between languages\n\n### When NOT to Use\n\n- Simple, quick tasks (overhead not worth it)\n- Tasks requiring immediate response (rate limits cause delays)\n- When context is already loaded and understood\n- Interactive refinement requiring conversation\n\n## Core Instructions\n\n### 1. Verify Installation\n\n```bash\ncommand -v gemini || which gemini\n```\n\n### 2. Basic Command Pattern\n\n```bash\ngemini \"[prompt]\" --yolo -o text 2>&1\n```\n\nKey flags:\n- `--yolo` or `-y`: Auto-approve all tool calls\n- `-o text`: Human-readable output\n- `-o json`: Structured output with stats\n- `-m gemini-2.5-flash`: Use faster model for simple tasks\n\n### 3. Critical Behavioral Notes\n\n**YOLO Mode Behavior**: Auto-approves tool calls but does NOT prevent planning prompts. Gemini may still present plans and ask \"Does this plan look good?\" Use forceful language:\n- \"Apply now\"\n- \"Start immediately\"\n- \"Do this without asking for confirmation\"\n\n**Rate Limits**: Free tier has 60 requests/min, 1000/day. CLI auto-retries with backoff. Expect messages like \"quota will reset after Xs\".\n\n### 4. Output Processing\n\nFor JSON output (`-o json`), parse:\n```json\n{\n  \"response\": \"actual content\",\n  \"stats\": {\n    \"models\": { \"tokens\": {...} },\n    \"tools\": { \"byName\": {...} }\n  }\n}\n```\n\n## Quick Reference Commands\n\n### Code Generation\n```bash\ngemini \"Create [description] with [features]. Output complete file content.\" --yolo -o text\n```\n\n### Code Review\n```bash\ngemini \"Review [file] for: 1) features, 2) bugs/security issues, 3) improvements\" -o text\n```\n\n### Bug Fixing\n```bash\ngemini \"Fix these bugs in [file]: [list]. Apply fixes now.\" --yolo -o text\n```\n\n### Test Generation\n```bash\ngemini \"Generate [Jest/pytest] tests for [file]. Focus on [areas].\" --yolo -o text\n```\n\n### Documentation\n```bash\ngemini \"Generate JSDoc for all functions in [file]. Output as markdown.\" --yolo -o text\n```\n\n### Architecture Analysis\n```bash\ngemini \"Use codebase_investigator to analyze this project\" -o text\n```\n\n### Web Research\n```bash\ngemini \"What are the latest [topic]? Use Google Search.\" -o text\n```\n\n### Faster Model (Simple Tasks)\n```bash\ngemini \"[prompt]\" -m gemini-2.5-flash -o text\n```\n\n## Error Handling\n\n### Rate Limit Exceeded\n- CLI auto-retries with backoff\n- Use `-m gemini-2.5-flash` for lower priority tasks\n- Run in background for long operations\n\n### Command Failures\n- Check JSON output for detailed error stats\n- Verify Gemini is authenticated: `gemini --version`\n- Check `~/.gemini/settings.json` for config issues\n\n### Validation After Generation\nAlways verify Gemini's output:\n- Check for security vulnerabilities (XSS, injection)\n- Test functionality matches requirements\n- Review code style consistency\n- Verify dependencies are appropriate\n\n## Integration Workflow\n\n### Standard Generate-Review-Fix Cycle\n\n```bash\n# 1. Generate\ngemini \"Create [code]\" --yolo -o text\n\n# 2. Review (Gemini reviews its own work)\ngemini \"Review [file] for bugs and security issues\" -o text\n\n# 3. Fix identified issues\ngemini \"Fix [issues] in [file]. Apply now.\" --yolo -o text\n```\n\n### Background Execution\n\nFor long tasks, run in background and monitor:\n```bash\ngemini \"[long task]\" --yolo -o text 2>&1 &\n# Monitor with BashOutput tool\n```\n\n## Gemini's Unique Capabilities\n\nThese tools are available only through Gemini:\n\n1. **google_web_search** - Real-time internet search via Google\n2. **codebase_investigator** - Deep architectural analysis\n3. **save_memory** - Cross-session persistent memory\n\n## Configuration\n\n### Project Context (Optional)\n\nCreate `.gemini/GEMINI.md` in project root for persistent context that Gemini will automatically read.\n\n### Session Management\n\nList sessions: `gemini --list-sessions`\nResume session: `echo \"follow-up\" | gemini -r [index] -o text`\n\n## See Also\n\n- `reference.md` - Complete command and flag reference\n- `templates.md` - Prompt templates for common operations\n- `patterns.md` - Advanced integration patterns\n- `tools.md` - Gemini's built-in tools documentation"
    },
    "marketplace": {
      "hasMarketplaceJson": false
    },
    "internal": {
      "syncedAt": "2026-01-08T00:22:51.461Z",
      "version": 1
    }
  },
  "moido1092-algo-sensei": {
    "id": "moido1092-algo-sensei",
    "name": "algo-sensei",
    "description": "Your personal DSA & LeetCode mentor. Use for problem explanations, progressive hints, code reviews, mock interviews, pattern recognition, complexity analysis, and custom problem generation. Automatically adapts to your learning style and request type.",
    "repo": {
      "owner": "moido1092",
      "name": "algo-sensei",
      "fullName": "moido1092/algo-sensei",
      "url": "https://github.com/moido1092/algo-sensei",
      "defaultBranch": "main"
    },
    "metadata": {
      "stars": 1,
      "forks": 0,
      "language": null,
      "topics": [
        "ai",
        "ai-tutor",
        "assistant",
        "claude",
        "claude-ai",
        "claude-code",
        "claude-skills",
        "coding-interview",
        "coding-interviews",
        "competitive-programming",
        "data-structures",
        "dsa",
        "faang",
        "helper",
        "mock-interview",
        "problem-solving",
        "pyt",
        "technical-interview"
      ],
      "createdAt": "2025-11-12T11:00:46Z",
      "updatedAt": "2026-01-07T23:02:35Z",
      "pushedAt": "2026-01-07T23:02:31Z",
      "license": "MIT License"
    },
    "category": "tools",
    "tags": [
      "ai",
      "ai-tutor",
      "assistant",
      "claude",
      "claude-ai",
      "claude-code",
      "claude-skills",
      "coding-interview",
      "coding-interviews",
      "competitive-programming"
    ],
    "skillMd": {
      "raw": "---\nname: algo-sensei\ndescription: Your personal DSA & LeetCode mentor. Use for problem explanations, progressive hints, code reviews, mock interviews, pattern recognition, complexity analysis, and custom problem generation. Automatically adapts to your learning style and request type.\n---\n\n# Algo Sensei ðŸ¥‹\n\nYou are Algo Sensei, a master DSA (Data Structures & Algorithms) mentor specialized in helping developers master LeetCode problems and ace technical interviews. Your teaching philosophy emphasizes understanding over memorization, pattern recognition, and building intuition.\n\n## Core Principles\n\n1. **Socratic Method**: Guide through questions rather than giving direct answers\n2. **Progressive Disclosure**: Start with hints, only reveal more if stuck\n3. **Pattern Recognition**: Help identify which algorithmic pattern applies\n4. **Deep Understanding**: Always explain the \"why\" behind solutions\n5. **Interview Readiness**: Simulate real interview conditions and feedback\n\n## Intelligence Routing\n\nAnalyze the user's request and automatically engage the appropriate mode:\n\n### Mode Detection Rules\n\n**TUTOR MODE** - Trigger when user:\n- Asks to \"explain\" a concept/problem\n- Says \"I don't understand\"\n- Requests \"teach me\" or \"help me learn\"\n- Asks \"what is\" or \"how does X work\"\n- Is clearly a beginner needing foundational help\n\n**HINT MODE** - Trigger when user:\n- Says \"give me a hint\" or \"I'm stuck\"\n- Provides a problem and asks for \"guidance\"\n- Says \"don't tell me the answer\"\n- Requests \"progressive hints\"\n- Wants to \"figure it out myself\"\n\n**REVIEW MODE** - Trigger when user:\n- Shares code and asks for \"review\" or \"feedback\"\n- Says \"is this optimal?\" or \"can I improve this?\"\n- Requests complexity analysis\n- Asks \"what's wrong with my solution?\"\n- Wants code optimization suggestions\n\n**INTERVIEW MODE** - Trigger when user:\n- Says \"mock interview\" or \"practice interview\"\n- Asks you to \"be the interviewer\"\n- Requests \"interview simulation\"\n- Wants to practice explaining solutions verbally\n\n**PATTERN MAPPER MODE** - Trigger when user:\n- Asks \"what pattern is this?\"\n- Says \"I can't figure out the approach\"\n- Requests \"similar problems\"\n- Wants to know \"which technique to use\"\n- Asks about problem categorization\n\n## Mode-Specific Instructions\n\n### When TUTOR MODE is detected:\nLoad and follow instructions from `modes/tutor-mode.md`\n\n### When HINT MODE is detected:\nLoad and follow instructions from `modes/hint-mode.md`\n\n### When REVIEW MODE is detected:\nLoad and follow instructions from `modes/review-mode.md`\n\n### When INTERVIEW MODE is detected:\nLoad and follow instructions from `modes/interview-mode.md`\n\n### When PATTERN MAPPER MODE is detected:\nLoad and follow instructions from `modes/pattern-mapper-mode.md`\n\n## Supporting Resources\n\n### Pattern Recognition\nWhen discussing patterns, draw from your comprehensive knowledge of all algorithmic patterns. You have deep understanding of Two Pointers, Sliding Window, Dynamic Programming, Binary Search, Graph algorithms, Backtracking, Tree traversal, Heaps, Tries, Monotonic Stack, and many more.\n\n### Solution Structure\nWhen providing solutions, follow format in `templates/solutions/solution-template.md`\n\n### Reference Materials\nUse `docs/dsa-cheatsheet.md` for quick reference on time/space complexities\n\n## Communication Style\n\n- **Encouraging but Honest**: Celebrate progress, but point out mistakes directly\n- **Concise**: Keep explanations tight and focused\n- **Visual**: Use ASCII diagrams when helpful\n- **Example-Driven**: Always provide concrete examples\n- **Question-Based**: Ask leading questions to build understanding\n\n## Complexity Analysis Standards\n\nAlways provide:\n- Time Complexity: Best, Average, Worst case\n- Space Complexity: Auxiliary space used\n- Trade-offs: Explain why this approach vs alternatives\n\n## Multi-Language Support\n\nSupport solutions in any programming language the user requests:\n- **Primary languages**: Python, JavaScript, Java, C++, Go, TypeScript, Rust\n- **Also supported**: Kotlin, Swift, Ruby, PHP, C#, Scala, and more\n\n**Default behavior:**\n- Ask user for language preference if not specified\n- Adapt examples to their chosen language\n- Provide language-specific idioms and best practices\n\n## Ethics & Learning\n\n- **Never** just hand out complete solutions without explanation\n- **Always** encourage understanding the approach first\n- **Emphasize** that the goal is learning, not just solving\n- **Discourage** memorization, encourage pattern thinking\n\n## Session Memory\n\nTrack within a session:\n- User's apparent skill level\n- Patterns they struggle with\n- Language preference\n- Learning style (visual, verbal, example-based)\n\nAdapt your teaching based on these observations.\n\n---\n\n**Ready to train? What challenge are you working on today?**\n",
      "frontmatter": {
        "name": "algo-sensei",
        "description": "Your personal DSA & LeetCode mentor. Use for problem explanations, progressive hints, code reviews, mock interviews, pattern recognition, complexity analysis, and custom problem generation. Automatically adapts to your learning style and request type."
      },
      "content": "# Algo Sensei ðŸ¥‹\n\nYou are Algo Sensei, a master DSA (Data Structures & Algorithms) mentor specialized in helping developers master LeetCode problems and ace technical interviews. Your teaching philosophy emphasizes understanding over memorization, pattern recognition, and building intuition.\n\n## Core Principles\n\n1. **Socratic Method**: Guide through questions rather than giving direct answers\n2. **Progressive Disclosure**: Start with hints, only reveal more if stuck\n3. **Pattern Recognition**: Help identify which algorithmic pattern applies\n4. **Deep Understanding**: Always explain the \"why\" behind solutions\n5. **Interview Readiness**: Simulate real interview conditions and feedback\n\n## Intelligence Routing\n\nAnalyze the user's request and automatically engage the appropriate mode:\n\n### Mode Detection Rules\n\n**TUTOR MODE** - Trigger when user:\n- Asks to \"explain\" a concept/problem\n- Says \"I don't understand\"\n- Requests \"teach me\" or \"help me learn\"\n- Asks \"what is\" or \"how does X work\"\n- Is clearly a beginner needing foundational help\n\n**HINT MODE** - Trigger when user:\n- Says \"give me a hint\" or \"I'm stuck\"\n- Provides a problem and asks for \"guidance\"\n- Says \"don't tell me the answer\"\n- Requests \"progressive hints\"\n- Wants to \"figure it out myself\"\n\n**REVIEW MODE** - Trigger when user:\n- Shares code and asks for \"review\" or \"feedback\"\n- Says \"is this optimal?\" or \"can I improve this?\"\n- Requests complexity analysis\n- Asks \"what's wrong with my solution?\"\n- Wants code optimization suggestions\n\n**INTERVIEW MODE** - Trigger when user:\n- Says \"mock interview\" or \"practice interview\"\n- Asks you to \"be the interviewer\"\n- Requests \"interview simulation\"\n- Wants to practice explaining solutions verbally\n\n**PATTERN MAPPER MODE** - Trigger when user:\n- Asks \"what pattern is this?\"\n- Says \"I can't figure out the approach\"\n- Requests \"similar problems\"\n- Wants to know \"which technique to use\"\n- Asks about problem categorization\n\n## Mode-Specific Instructions\n\n### When TUTOR MODE is detected:\nLoad and follow instructions from `modes/tutor-mode.md`\n\n### When HINT MODE is detected:\nLoad and follow instructions from `modes/hint-mode.md`\n\n### When REVIEW MODE is detected:\nLoad and follow instructions from `modes/review-mode.md`\n\n### When INTERVIEW MODE is detected:\nLoad and follow instructions from `modes/interview-mode.md`\n\n### When PATTERN MAPPER MODE is detected:\nLoad and follow instructions from `modes/pattern-mapper-mode.md`\n\n## Supporting Resources\n\n### Pattern Recognition\nWhen discussing patterns, draw from your comprehensive knowledge of all algorithmic patterns. You have deep understanding of Two Pointers, Sliding Window, Dynamic Programming, Binary Search, Graph algorithms, Backtracking, Tree traversal, Heaps, Tries, Monotonic Stack, and many more.\n\n### Solution Structure\nWhen providing solutions, follow format in `templates/solutions/solution-template.md`\n\n### Reference Materials\nUse `docs/dsa-cheatsheet.md` for quick reference on time/space complexities\n\n## Communication Style\n\n- **Encouraging but Honest**: Celebrate progress, but point out mistakes directly\n- **Concise**: Keep explanations tight and focused\n- **Visual**: Use ASCII diagrams when helpful\n- **Example-Driven**: Always provide concrete examples\n- **Question-Based**: Ask leading questions to build understanding\n\n## Complexity Analysis Standards\n\nAlways provide:\n- Time Complexity: Best, Average, Worst case\n- Space Complexity: Auxiliary space used\n- Trade-offs: Explain why this approach vs alternatives\n\n## Multi-Language Support\n\nSupport solutions in any programming language the user requests:\n- **Primary languages**: Python, JavaScript, Java, C++, Go, TypeScript, Rust\n- **Also supported**: Kotlin, Swift, Ruby, PHP, C#, Scala, and more\n\n**Default behavior:**\n- Ask user for language preference if not specified\n- Adapt examples to their chosen language\n- Provide language-specific idioms and best practices\n\n## Ethics & Learning\n\n- **Never** just hand out complete solutions without explanation\n- **Always** encourage understanding the approach first\n- **Emphasize** that the goal is learning, not just solving\n- **Discourage** memorization, encourage pattern thinking\n\n## Session Memory\n\nTrack within a session:\n- User's apparent skill level\n- Patterns they struggle with\n- Language preference\n- Learning style (visual, verbal, example-based)\n\nAdapt your teaching based on these observations.\n\n---\n\n**Ready to train? What challenge are you working on today?**"
    },
    "marketplace": {
      "hasMarketplaceJson": false
    },
    "internal": {
      "syncedAt": "2026-01-08T00:24:49.732Z",
      "version": 1
    }
  },
  "maryanohit549-wiggle-claude-skill": {
    "id": "maryanohit549-wiggle-claude-skill",
    "name": "wiggle",
    "description": "Create animated logo files (Lottie JSON, GIF, MP4) from static logo images. This skill should be used when users provide a logo image (PNG/SVG/JPG) and request any kind of logo animation, motion graphics, animated logo effect, waveform animation, bouncing logo, rotating logo, pulsing logo, wiggling logo, or ask to \"animate my logo\" or \"make my logo move\". Outputs standalone animation files (not React/HTML artifacts). Generates Lottie JSON with automatic GIF/MP4 rendering, perfect loop validation, and professional motion design patterns.",
    "repo": {
      "owner": "Maryanohit549",
      "name": "wiggle-claude-skill",
      "fullName": "Maryanohit549/wiggle-claude-skill",
      "url": "https://github.com/Maryanohit549/wiggle-claude-skill",
      "defaultBranch": "main"
    },
    "metadata": {
      "stars": 2,
      "forks": 0,
      "language": "Python",
      "topics": [
        "ai",
        "animation",
        "claude",
        "claude-ai",
        "claude-code",
        "claude-desktop",
        "claude-skills",
        "logo",
        "lottie",
        "lottie-animation",
        "lottie-animations"
      ],
      "createdAt": "2025-11-02T15:34:45Z",
      "updatedAt": "2026-01-07T23:01:11Z",
      "pushedAt": "2026-01-07T23:01:08Z",
      "license": "Other"
    },
    "category": "development",
    "tags": [
      "ai",
      "animation",
      "claude",
      "claude-ai",
      "claude-code",
      "claude-desktop",
      "claude-skills",
      "logo",
      "lottie",
      "lottie-animation"
    ],
    "skillMd": {
      "raw": "---\nname: wiggle\ndescription: Create animated logo files (Lottie JSON, GIF, MP4) from static logo images. This skill should be used when users provide a logo image (PNG/SVG/JPG) and request any kind of logo animation, motion graphics, animated logo effect, waveform animation, bouncing logo, rotating logo, pulsing logo, wiggling logo, or ask to \"animate my logo\" or \"make my logo move\". Outputs standalone animation files (not React/HTML artifacts). Generates Lottie JSON with automatic GIF/MP4 rendering, perfect loop validation, and professional motion design patterns.\nlicense: Complete terms in LICENSE.txt\n---\n\n# Wiggle Logo Animator\n\nCreate professional logo animations using Lottie JSON format. Ingest existing logos (PNG/SVG/JPG) or generate simple text-based logos, then animate them with professionally-crafted motion patterns. Output includes Lottie JSON with automatic GIF preview rendering and optional MP4 export.\n\n## When to Use This Skill\n\nTrigger this skill when users request:\n- \"Animate my logo\" / \"Create a logo animation\"\n- \"Make my logo wiggle/bounce/rotate/pulse\"\n- \"Animated waveform effect for my logo\"\n- \"Motion graphics for my brand logo\"\n- \"Lottie animation for my brand\"\n- Logo entrance, loop, or loading animations\n- Any animation effect applied to a provided logo image\n\n**Important**: This skill outputs standalone animation files (Lottie JSON, GIF, MP4), NOT interactive React/HTML artifacts. If user wants an interactive tool or web component, defer to artifacts-builder skill.\n\n---\n\n## Core Workflow\n\n### 1. Define Motion Philosophy (30 seconds - MANDATORY!)\n\n**Before creating any animation**, answer these three questions:\n\n1. **What personality does this brand have?**\n   (playful, professional, bold, elegant, innovative, trustworthy)\n\n2. **What emotion should the animation evoke?**\n   (excitement, trust, creativity, confidence, curiosity)\n\n3. **What motion metaphor fits?**\n   (organic growth, mechanical precision, energetic burst, elegant reveal, rhythmic pulse)\n\n**Example:**\n\"Canva = Creative tool brand â†’ Playful energy + organic growth â†’ Simultaneous entrance with pulse\"\n\nSee [Animation Philosophy](#animation-philosophy) section below for detailed framework.\n\n---\n\n### 2. Analyze Logo Structure (30 seconds - MANDATORY!)\n\n**Before creating animation**, understand what you're working with:\n\n```bash\n# For SVG logos - identify elements\npython scripts/extract_svg_elements.py logo.svg --list\n```\n\n**Quick decision tree:**\n\n```\nLogo has text?\n  â”œâ”€ YES â†’ Read references/text_animation_guide.md FIRST\n  â””â”€ NO  â†’ Continue with standard workflow\n\nMultiple elements (icon + text)?\n  â”œâ”€ YES â†’ Extract separately, decide timing (simultaneous vs staggered)\n  â””â”€ NO  â†’ Animate as single unit\n\nSVG or PNG?\n  â”œâ”€ SVG â†’ Can extract elements cleanly\n  â””â”€ PNG â†’ Limited to single-logo animations\n```\n\n---\n\n### 3. Prepare Assets\n\n```bash\n# Single logo (simple animation)\npython scripts/prepare_logo.py logo.png --max-size 500 --optimize\n# Creates: logo_optimized.png (30-50KB) + logo_base64.txt\n\n# Multi-element logo (extract FIRST, then convert)\npython scripts/extract_svg_elements.py logo.svg --output-dir ./elements/\npython scripts/prepare_logo.py elements/icon.svg --max-size 200\npython scripts/prepare_logo.py elements/text.svg --max-size 250\n```\n\n**Size guidelines:**\n- Full logo (single): 500-600px\n- Icon elements: 100-200px\n- Text elements: 200-300px\n\n---\n\n### 4. Create Lottie JSON Animation\n\n**Use EXTERNAL references during development:**\n\n```json\n{\n  \"v\": \"5.7.4\",\n  \"fr\": 60,\n  \"ip\": 0,\n  \"op\": 180,\n  \"w\": 800,\n  \"h\": 800,\n  \"layers\": [{\n    \"ind\": 1,\n    \"ty\": 2,\n    \"nm\": \"Logo\",\n    \"refId\": \"logo_image\",\n    \"ks\": {\n      \"o\": {\n        \"a\": 1,\n        \"k\": [\n          {\"t\": 0, \"s\": [0], \"e\": [100], \"i\": {\"x\": [0.42], \"y\": [1]}, \"o\": {\"x\": [0.58], \"y\": [0]}},\n          {\"t\": 60, \"s\": [100]}\n        ]\n      }\n    }\n  }],\n  \"assets\": [{\"id\": \"logo_image\", \"w\": 512, \"h\": 512, \"p\": \"logo_optimized.png\", \"e\": 0}]\n}\n```\n\n**Critical:** Use `\"e\": 0` (external reference) during development to avoid Cairo memory errors.\n\nSee [Animation Patterns](#animation-pattern-quick-reference) below for common effects, or [references/detailed_examples.md](references/detailed_examples.md) for full code examples.\n\n---\n\n### 5. Validate\n\n```bash\n# Check Lottie structure (warns about large embedded assets)\npython scripts/validate_lottie.py logo_animation.json\n\n# Check loop quality (if creating looping animation)\npython scripts/validate_loop.py logo_animation.json\n```\n\n---\n\n### 6. Render\n\n```bash\n# RECOMMENDED: Preview first (renders only first N frames) - saves time!\npython scripts/render_lottie.py logo_animation.json preview.gif --preview-frames 60\n\n# Alternative: Test render mode (200x200, 15fps with confirmation prompt)\npython scripts/render_lottie.py logo_animation.json logo.gif --test-render\n\n# If preview looks good â†’ Render full animation\npython scripts/render_lottie.py logo_animation.json logo.gif\n\n# Optional: MP4 export (better compression than GIF)\npython scripts/render_lottie.py logo_animation.json logo.mp4\n\n# Optional: Batch export all formats\npython scripts/batch_export.py logo_animation.json ./output gif,mp4,json\n```\n\n**Important notes:**\n- Assets are resolved **relative to the Lottie JSON file location** (not current working directory)\n- Asset validation runs automatically before rendering\n- Output verification detects blank/corrupted files\n- Use `--preview-frames N` to render only first N frames for quick validation\n\n---\n\n### 7. Optional: Embed for Distribution\n\n**After successful rendering**, optionally convert to embedded base64 for standalone distribution:\n\n```json\n// Replace external reference with base64 from logo_base64.txt\n\"assets\": [{\"id\": \"logo_image\", \"p\": \"data:image/png;base64,...\", \"e\": 1}]\n```\n\n**Note:** Keep external version for future edits/rendering!\n\n---\n\n## Animation Philosophy\n\n### The Two-Phase Approach\n\n**Phase 1: Define Philosophy** (think before implementing)\n\n1. What personality does this brand have?\n2. What emotion should the animation evoke?\n3. What motion metaphor fits?\n\n**Phase 2: Express Through Technical Choices**\n\n- **Choose properties** that express philosophy (position/scale/rotation/opacity)\n- **Select easing** that matches personality (ease-out=confident, bounce=playful)\n- **Set timing** that aligns with emotion (fast=energetic, slow=elegant)\n\n### Philosophy Examples\n\n**\"Confident Professionalism\"**\n- Philosophy: Trustworthy, established, competent\n- Expression: Slow ease-out fade (0â†’100% opacity) + gentle scale (95%â†’100%)\n- Timing: 2s duration, no overshoot\n- Example: [references/real-world-examples/slack-hover-pinch.json](references/real-world-examples/slack-hover-pinch.json)\n\n**\"Playful Energy\"**\n- Philosophy: Fun, approachable, memorable\n- Expression: Bounce entrance with overshoot\n- Timing: 1s duration, back easing (0.6/-0.28)\n- Example: [references/real-world-examples/reddit-hover-pinch.json](references/real-world-examples/reddit-hover-pinch.json)\n\n**\"Audio/Speech Brand\"**\n- Philosophy: Sound, rhythm, waveforms, dynamic\n- Expression: Vertical waveform with dense keyframes (30-45 keyframes, 60fps)\n- Timing: 3s loop, organic easing (0.25/0.75)\n- **Critical:** See \"Organic/Continuous Motion\" in Motion Types section below\n\nMore examples in [references/preset_library.md](references/preset_library.md) and [references/animation_theory.md](references/animation_theory.md).\n\n---\n\n## Motion Type Quick Reference\n\nChoose motion type based on brand personality:\n\n### Static/Corporate Motion\nProfessional brands (B2B, finance, legal)\n\n**Parameters:**\n- Keyframes: 8-12 (sparse, deliberate)\n- Easing: `0.42/0.58` (standard ease-in-out)\n- FPS: 30\n- Duration: 1.5-2s\n\n**Use for:** Corporate logos, B2B brands, professional presentations\n\n---\n\n### Organic/Continuous Motion\nAudio, music, speech AI, nature brands\n\n**Parameters:**\n- Keyframes: 25-45 â† **Critical for smoothness**\n- Easing: `0.25/0.75` (softer, more organic)\n- FPS: 60 â† **Essential for fluidity**\n- Duration: 3s\n\n**Use for:** Audio apps, music platforms, speech AI, organic products\n\n**Example:** Vertical bar waveform pattern in [references/detailed_examples.md](references/detailed_examples.md#7-vertical-bar-waveform-organic-motion)\n\n---\n\n### Bold/Attention-Grabbing\nStartups, social media, marketing\n\n**Parameters:**\n- Keyframes: 15-25\n- Easing: `0.34/1.56` (playful bounce) or `0.6/-0.28` (back overshoot)\n- FPS: 60\n- Duration: 0.8-1.5s\n\n**Use for:** Startup logos, social media intros, marketing campaigns\n\n---\n\n### Cinematic/Complex\nPremium brands, film production\n\n**Parameters:**\n- Keyframes: 50-120\n- Easing: Custom bezier curves, variable timing\n- FPS: 60-120\n- Duration: 3-5s\n\n**Use for:** Luxury brands, film intros, high-end agency work\n\n---\n\n## Animation Pattern Quick Reference\n\n### Single-Element Patterns\n\n| Pattern | Duration | Properties | Use Case |\n|---------|----------|------------|----------|\n| **Fade + Gentle Scale** | 1.5s | Opacity: 0â†’100%, Scale: 95â†’100% | Corporate entrances |\n| **Bounce Entrance** | 1.2s | Position, Scale, Opacity | Energetic brands |\n| **Scale Pulse** | 3s loop | Scale: 100â†’103â†’100% | Idle states, CTAs |\n| **Smooth Rotation** | 10s loop | Rotation: 0â†’360Â° | Loading, tech logos |\n| **Wiggle/Jello** | 0.8s | Rotation: Â±5Â° oscillation | Playful notifications |\n\n**Full code examples:** [references/detailed_examples.md](references/detailed_examples.md)\n\n---\n\n### Multi-Element Coordination\n\n**Pattern 1: Simultaneous Entrance**\nBoth elements appear together (cohesive brand)\n\n```json\nIcon: {\"t\": 0, \"s\": [0]}, {\"t\": 60, \"s\": [100]}\nText: {\"t\": 0, \"s\": [0]}, {\"t\": 60, \"s\": [100]}\n// Both start at t:0 â†’ Synchronized\n```\n\n**Pattern 2: Staggered Entrance**\nIcon establishes first, text reinforces (storytelling)\n\n```json\nIcon: {\"t\": 0, \"s\": [0]}, {\"t\": 45, \"s\": [100]}\nText: {\"t\": 30, \"s\": [0]}, {\"t\": 75, \"s\": [100]}\n// Text delayed 30 frames (0.5s at 60fps)\n```\n\n**Timing guidelines:**\n- 15 frames (0.25s): Subtle stagger\n- 30 frames (0.5s): Noticeable sequence â† Most common\n- 45 frames (0.75s): Dramatic two-act reveal\n\n**Full patterns:** [references/detailed_examples.md#multi-element-coordination](references/detailed_examples.md#multi-element-coordination)\n\n---\n\n## User Intent Classification\n\nAlways classify user intent to select appropriate animation style:\n\n| Intent | Keyframes | Easing | FPS | Duration | Motion |\n|--------|-----------|--------|-----|----------|--------|\n| **Subtle/Professional** | 8-12 | 0.42/0.58 | 30 | 1.5-2s | Slow, controlled, minimal rotation |\n| **Bold/Attention** | 15-25 | 0.34/1.56 | 60 | 0.8-1.5s | Medium-fast, dynamic, Â±10-20% scale |\n| **Playful/Creative** | 12-20 | 0.34/1.56 | 30-60 | 1-2s | Bouncy, exaggerated, wiggle effects |\n| **Organic/Continuous** | 25-45 | 0.25/0.75 | 60 | 3s | Waveforms, pulses, flowing rhythms |\n\n**Default:** Provide animation rather than asking questions, unless user explicitly requests options.\n\n---\n\n## Known Limitations\n\n### Asset Path Resolution\n\n**Current behavior:**\n- External assets (PNGs/SVGs) are resolved **relative to the Lottie JSON file location**\n- The renderer changes the working directory to the JSON file's directory during rendering\n- Asset validation runs automatically before rendering begins\n\n**Example:**\n```\nproject/\nâ”œâ”€â”€ animations/\nâ”‚   â””â”€â”€ logo_animation.json  (references \"logo_optimized.png\")\nâ””â”€â”€ logo_optimized.png\n\n# This will FAIL - asset not found\n```\n\n**Solution:** Place assets in the same directory as the JSON file:\n```\nproject/animations/\nâ”œâ”€â”€ logo_animation.json\nâ””â”€â”€ logo_optimized.png  # âœ… Correct location\n```\n\n### Embedded Base64 vs External References\n\n**Embedded base64** (`\"e\": 1`):\n- **Pros:** Standalone file, easy distribution\n- **Cons:** Cairo MemoryError for images >100KB, larger file sizes, not editable\n\n**External references** (`\"e\": 0`):\n- **Pros:** No memory issues, smaller JSON files, easy to update assets\n- **Cons:** Requires keeping asset files alongside JSON\n\n**Recommended workflow:**\n1. Use external references during development/rendering\n2. Optionally embed base64 AFTER successful rendering for distribution\n3. Keep external version for future edits\n\n---\n\n## Critical Warnings\n\n### âŒ Common Mistakes to Avoid\n\n1. **Creating animation before defining philosophy** â†’ Random trial-and-error wastes 15-30 minutes\n2. **Using PIL ImageDraw to recreate logo text** â†’ Creates DIFFERENT text, not your logo text\n3. **Embedding base64 before rendering** â†’ Cairo MemoryError crash (images >100KB)\n4. **Using 1000px for small elements** â†’ Huge files (400KB+), memory issues\n5. **Skipping logo analysis** â†’ Wrong workflow, have to restart\n6. **Forgetting loop validation** â†’ Visible jump when animation loops\n7. **Skipping preview renders** â†’ Waste time on full renders before validating concept\n8. **Rendering full SVG then cropping** â†’ Fuzzy edges, massive file sizes\n\n**Full list with code examples:** [references/anti_patterns.md](references/anti_patterns.md)\n\n---\n\n### âš ï¸ Text in Logos - CRITICAL\n\n**If logo contains text**, you MUST follow specialized workflow:\n\n1. **Extract text from logo SVG** (do NOT recreate with PIL ImageDraw)\n2. **Choose appropriate text animation method** (fade/stroke/transform)\n3. **Implement proper synchronization** with other elements\n\n**See:** [references/text_animation_guide.md](references/text_animation_guide.md) for complete guide\n\n---\n\n### âš ï¸ External References Required\n\n**Always use external file references during development/rendering:**\n\n```json\n// âœ… CORRECT: External reference\n\"assets\": [{\"id\": \"logo\", \"p\": \"logo_optimized.png\", \"e\": 0}]\n\n// âŒ WRONG: Embedded base64 (causes Cairo crash if >100KB)\n\"assets\": [{\"id\": \"logo\", \"p\": \"data:image/png;base64,...\", \"e\": 1}]\n```\n\n**Why:** Cairo renderer crashes with embedded images >100KB. Use external during development, optionally embed AFTER successful rendering.\n\n---\n\n## Helper Scripts Quick Reference\n\n| Script | Purpose | Example |\n|--------|---------|---------|\n| `prepare_logo.py` | Optimize and convert logo images | `python scripts/prepare_logo.py logo.png --max-size 500` |\n| `extract_svg_elements.py` | Extract elements from SVG | `python scripts/extract_svg_elements.py logo.svg --list` |\n| `validate_lottie.py` | Check Lottie structure | `python scripts/validate_lottie.py animation.json` |\n| `validate_loop.py` | Verify perfect loop | `python scripts/validate_loop.py animation.json` |\n| `render_lottie.py` | Render to GIF/MP4 (with asset validation) | `python scripts/render_lottie.py animation.json output.gif` |\n| `render_lottie.py --preview-frames N` | Quick preview (first N frames) | `python scripts/render_lottie.py animation.json preview.gif --preview-frames 60` |\n| `render_lottie.py --test-render` | Test mode with size warnings | `python scripts/render_lottie.py animation.json test.gif --test-render` |\n| `batch_export.py` | Export multiple formats | `python scripts/batch_export.py animation.json ./output gif,mp4` |\n\n**New features in render_lottie.py:**\n- âœ… Automatic asset validation (checks for missing external files)\n- âœ… Asset path resolution (relative to JSON file location)\n- âœ… Output verification (detects blank/corrupted files)\n- âœ… Preview mode (`--preview-frames N`) - renders only first N frames\n- âœ… Test mode (`--test-render`) - small test render with confirmation prompt\n\n**Detailed usage:** [references/script_usage.md](references/script_usage.md)\n\n---\n\n## Lottie JSON Fundamentals\n\n### Basic Structure\n\n```json\n{\n  \"v\": \"5.7.4\",           // Lottie version\n  \"fr\": 60,               // Frame rate\n  \"ip\": 0,                // In point (start frame)\n  \"op\": 180,              // Out point (end frame)\n  \"w\": 800,               // Width\n  \"h\": 800,               // Height\n  \"layers\": [...],        // Animation layers\n  \"assets\": [...]         // Image/asset references\n}\n```\n\n### Layer Types\n\n- **Type 2 (Image Layer):** Most common - animates PNG/SVG images\n- **Type 4 (Shape Layer):** Programmatic geometry (circles, rectangles, paths)\n\n### Animated Properties\n\n- **`o`:** Opacity (0-100)\n- **`p`:** Position [x, y]\n- **`s`:** Scale [x%, y%]\n- **`r`:** Rotation (degrees)\n- **`a`:** Anchor point [x, y]\n\n### Keyframe Structure\n\n```json\n\"o\": {\n  \"a\": 1,  // Animated (1) or static (0)\n  \"k\": [\n    {\"t\": 0, \"s\": [0], \"e\": [100], \"i\": {...}, \"o\": {...}},\n    {\"t\": 60, \"s\": [100]}\n  ]\n}\n```\n\n- **`t`:** Time (frame number)\n- **`s`:** Start value\n- **`e`:** End value\n- **`i`:** In tangent (ease in)\n- **`o`:** Out tangent (ease out)\n\n**Complete specification:** [references/lottie_spec.md](references/lottie_spec.md)\n\n---\n\n## Easing Functions\n\n**Never use linear easing** - always use curves for professional motion.\n\n| Easing | Values | Feel | Use Case |\n|--------|--------|------|----------|\n| **Ease-in-out (standard)** | `0.42/0.58` | Balanced, professional | Corporate, general use |\n| **Organic** | `0.25/0.75` | Soft, natural | Audio brands, waveforms, continuous motion |\n| **Bounce** | `0.34/1.56` | Playful, energetic | Startups, playful brands |\n| **Back** | `0.6/-0.28` & `0.735/0.045` | Overshoot, dynamic | Bold marketing, attention-grabbing |\n\n**Theory and examples:** [references/animation_theory.md](references/animation_theory.md)\n\n---\n\n## Dependencies\n\n### Required\n```bash\npip install lottie[all]    # Lottie manipulation\npip install Pillow         # Image processing\npip install pycairo        # Cairo rendering (for GIF)\n```\n\n### Cairo Installation\n\n**macOS:**\n```bash\nbrew install cairo pkg-config\npip install pycairo\n```\n\n**Linux (Ubuntu/Debian):**\n```bash\nsudo apt-get install libcairo2-dev pkg-config python3-dev\npip install pycairo\n```\n\n**Verify:**\n```bash\npython3 -c \"import cairo; print('Cairo OK')\"\n```\n\n**Troubleshooting:** [references/troubleshooting.md#cairo-and-dependencies](references/troubleshooting.md#cairo-and-dependencies)\n\n---\n\n## Troubleshooting\n\n### Quick Fixes\n\n**Asset not found errors:**\n- **Cause:** Assets not in same directory as Lottie JSON\n- **Fix:** Move assets to JSON file's directory, or use absolute paths\n- **Validation:** Run `render_lottie.py` - it validates assets before rendering\n\n**Blank/corrupted output:**\n- **Cause:** Missing assets, wrong paths, or rendering errors\n- **Fix:** Check asset validation messages, verify file sizes (output <1KB indicates failure)\n- **Detection:** Output verification runs automatically after rendering\n\n**MemoryError during GIF rendering:**\n- **Cause:** Embedded base64 images >100KB\n- **Fix:** Use external reference (`\"e\": 0`) instead\n\n**Loop has visible jump:**\n- **Cause:** Last keyframe doesn't match first\n- **Fix:** Run `validate_loop.py` and ensure last frame = first frame\n\n**Text looks wrong:**\n- **Cause:** Used PIL ImageDraw to recreate text\n- **Fix:** Extract text from logo SVG with `extract_svg_elements.py`\n\n**Animation too choppy:**\n- **Cause:** Too few keyframes or wrong FPS\n- **Fix:** Add keyframes (25-45 for organic motion), use 60fps for continuous motion\n\n**Preview renders save time:**\n- **Tip:** Use `--preview-frames 60` to validate concept before full render\n- **Tip:** Use `--test-render` for interactive testing with size warnings\n\n**Comprehensive guide:** [references/troubleshooting.md](references/troubleshooting.md)\n\n---\n\n## Advanced References\n\n### Detailed Documentation\n\n- **[references/detailed_examples.md](references/detailed_examples.md)** - Full Lottie JSON code for all patterns\n- **[references/animation_theory.md](references/animation_theory.md)** - Motion design principles and easing theory\n- **[references/preset_library.md](references/preset_library.md)** - Complete preset collection with real-world examples\n- **[references/lottie_spec.md](references/lottie_spec.md)** - Lottie JSON specification details\n- **[references/script_usage.md](references/script_usage.md)** - Complete script documentation\n- **[references/text_animation_guide.md](references/text_animation_guide.md)** - Specialized text animation workflows\n- **[references/anti_patterns.md](references/anti_patterns.md)** - Common mistakes with full code examples\n- **[references/troubleshooting.md](references/troubleshooting.md)** - Comprehensive troubleshooting guide\n- **[references/real-world-examples/](references/real-world-examples/)** - Production animations from major brands\n\n---\n\n## File Size Guidelines\n\n**Target sizes for different use cases:**\n\n| Use Case | Lottie JSON | GIF | MP4 | Image Assets |\n|----------|-------------|-----|-----|--------------|\n| Email signature | 20-50KB | 500KB-1MB | 200-500KB | <30KB each |\n| Website hero | 30-80KB | 1-3MB | 500KB-1.5MB | <50KB each |\n| Social media | 50-150KB | 3-8MB | 1-3MB | <80KB each |\n| Splash screen | 30-100KB | 2-5MB | 800KB-2MB | <60KB each |\n\n**Optimization:** Use `scripts/optimize_lottie.py` to reduce file sizes by removing redundant keyframes and rounding values.\n\n---\n\n## Curated Presets\n\nQuick reference to common presets (full code in [references/preset_library.md](references/preset_library.md)):\n\n**Branding Styles:**\n- Corporate Subtle - Fade + gentle scale (1.5s)\n- Startup Energetic - Bounce + overshoot (1.2s)\n- Luxury Elegant - Slow fade + minimal scale (3s)\n- Tech Glitch - Digital disruption effect (1s)\n\n**Use Cases:**\n- Website Hero - Quick professional entrance (0.8s)\n- Email Signature - Subtle loop (3s)\n- Social Media Intro - Bold entrance (2s)\n- Splash Screen - Brand moment with exit (2.5s)\n\n**Real-World Examples:**\nStudy hover animations from major brands in [references/real-world-examples/](references/real-world-examples/):\n- Reddit - Playful elastic bounce\n- Slack - Professional restrained pinch\n- Medium - Gentle editorial fade\n- Flickr - Camera shutter effect\n- Discord - Character wink\n\n---\n\n## Quick Decision Checklist\n\nBefore creating animation, verify:\n\n- [ ] Defined motion philosophy (personality + emotion + metaphor)\n- [ ] Analyzed logo structure (text? multi-element? SVG or PNG?)\n- [ ] Chose correct workflow based on analysis\n- [ ] If text present: Read [references/text_animation_guide.md](references/text_animation_guide.md)\n- [ ] Using external references (`\"e\": 0`) during development\n- [ ] Element sizes appropriate (500px full logo, 100-250px elements)\n- [ ] Selected motion type (Static/Organic/Bold/Cinematic)\n- [ ] Chosen timing strategy (simultaneous vs staggered)\n- [ ] Will validate with preview render before full render\n- [ ] Will run `validate_loop.py` if creating loop\n\n**If all checked â†’ Proceed with confidence âœ…**\n\n---\n\n## Tips for Success\n\n1. **Philosophy first** - 30 seconds planning saves 15-30 minutes iteration\n2. **Analyze before animating** - Understand logo structure upfront\n3. **Preview early, preview often** - Test 30-60 frame versions before full render\n4. **External references during development** - Embed base64 only after successful rendering\n5. **Match motion to brand** - Corporate â‰  startup â‰  audio brand\n6. **Perfect loops matter** - Use `validate_loop.py` to verify\n7. **Size elements appropriately** - 100-250px for elements, not 1000px\n8. **Extract, don't recreate** - Never use PIL to recreate logo text\n9. **Validate before rendering** - Run `validate_lottie.py` and `validate_loop.py`\n10. **Read references when stuck** - Detailed docs available for every topic\n\n---\n\n**Remember:** The goal is creating motion that enhances brand identity, not random animation. Philosophy-first workflow ensures alignment from the start.\n",
      "frontmatter": {
        "name": "wiggle",
        "description": "Create animated logo files (Lottie JSON, GIF, MP4) from static logo images. This skill should be used when users provide a logo image (PNG/SVG/JPG) and request any kind of logo animation, motion graphics, animated logo effect, waveform animation, bouncing logo, rotating logo, pulsing logo, wiggling logo, or ask to \"animate my logo\" or \"make my logo move\". Outputs standalone animation files (not React/HTML artifacts). Generates Lottie JSON with automatic GIF/MP4 rendering, perfect loop validation, and professional motion design patterns.",
        "license": "Complete terms in LICENSE.txt"
      },
      "content": "# Wiggle Logo Animator\n\nCreate professional logo animations using Lottie JSON format. Ingest existing logos (PNG/SVG/JPG) or generate simple text-based logos, then animate them with professionally-crafted motion patterns. Output includes Lottie JSON with automatic GIF preview rendering and optional MP4 export.\n\n## When to Use This Skill\n\nTrigger this skill when users request:\n- \"Animate my logo\" / \"Create a logo animation\"\n- \"Make my logo wiggle/bounce/rotate/pulse\"\n- \"Animated waveform effect for my logo\"\n- \"Motion graphics for my brand logo\"\n- \"Lottie animation for my brand\"\n- Logo entrance, loop, or loading animations\n- Any animation effect applied to a provided logo image\n\n**Important**: This skill outputs standalone animation files (Lottie JSON, GIF, MP4), NOT interactive React/HTML artifacts. If user wants an interactive tool or web component, defer to artifacts-builder skill.\n\n---\n\n## Core Workflow\n\n### 1. Define Motion Philosophy (30 seconds - MANDATORY!)\n\n**Before creating any animation**, answer these three questions:\n\n1. **What personality does this brand have?**\n   (playful, professional, bold, elegant, innovative, trustworthy)\n\n2. **What emotion should the animation evoke?**\n   (excitement, trust, creativity, confidence, curiosity)\n\n3. **What motion metaphor fits?**\n   (organic growth, mechanical precision, energetic burst, elegant reveal, rhythmic pulse)\n\n**Example:**\n\"Canva = Creative tool brand â†’ Playful energy + organic growth â†’ Simultaneous entrance with pulse\"\n\nSee [Animation Philosophy](#animation-philosophy) section below for detailed framework.\n\n---\n\n### 2. Analyze Logo Structure (30 seconds - MANDATORY!)\n\n**Before creating animation**, understand what you're working with:\n\n```bash\n# For SVG logos - identify elements\npython scripts/extract_svg_elements.py logo.svg --list\n```\n\n**Quick decision tree:**\n\n```\nLogo has text?\n  â”œâ”€ YES â†’ Read references/text_animation_guide.md FIRST\n  â””â”€ NO  â†’ Continue with standard workflow\n\nMultiple elements (icon + text)?\n  â”œâ”€ YES â†’ Extract separately, decide timing (simultaneous vs staggered)\n  â””â”€ NO  â†’ Animate as single unit\n\nSVG or PNG?\n  â”œâ”€ SVG â†’ Can extract elements cleanly\n  â””â”€ PNG â†’ Limited to single-logo animations\n```\n\n---\n\n### 3. Prepare Assets\n\n```bash\n# Single logo (simple animation)\npython scripts/prepare_logo.py logo.png --max-size 500 --optimize\n# Creates: logo_optimized.png (30-50KB) + logo_base64.txt\n\n# Multi-element logo (extract FIRST, then convert)\npython scripts/extract_svg_elements.py logo.svg --output-dir ./elements/\npython scripts/prepare_logo.py elements/icon.svg --max-size 200\npython scripts/prepare_logo.py elements/text.svg --max-size 250\n```\n\n**Size guidelines:**\n- Full logo (single): 500-600px\n- Icon elements: 100-200px\n- Text elements: 200-300px\n\n---\n\n### 4. Create Lottie JSON Animation\n\n**Use EXTERNAL references during development:**\n\n```json\n{\n  \"v\": \"5.7.4\",\n  \"fr\": 60,\n  \"ip\": 0,\n  \"op\": 180,\n  \"w\": 800,\n  \"h\": 800,\n  \"layers\": [{\n    \"ind\": 1,\n    \"ty\": 2,\n    \"nm\": \"Logo\",\n    \"refId\": \"logo_image\",\n    \"ks\": {\n      \"o\": {\n        \"a\": 1,\n        \"k\": [\n          {\"t\": 0, \"s\": [0], \"e\": [100], \"i\": {\"x\": [0.42], \"y\": [1]}, \"o\": {\"x\": [0.58], \"y\": [0]}},\n          {\"t\": 60, \"s\": [100]}\n        ]\n      }\n    }\n  }],\n  \"assets\": [{\"id\": \"logo_image\", \"w\": 512, \"h\": 512, \"p\": \"logo_optimized.png\", \"e\": 0}]\n}\n```\n\n**Critical:** Use `\"e\": 0` (external reference) during development to avoid Cairo memory errors.\n\nSee [Animation Patterns](#animation-pattern-quick-reference) below for common effects, or [references/detailed_examples.md](references/detailed_examples.md) for full code examples.\n\n---\n\n### 5. Validate\n\n```bash\n# Check Lottie structure (warns about large embedded assets)\npython scripts/validate_lottie.py logo_animation.json\n\n# Check loop quality (if creating looping animation)\npython scripts/validate_loop.py logo_animation.json\n```\n\n---\n\n### 6. Render\n\n```bash\n# RECOMMENDED: Preview first (renders only first N frames) - saves time!\npython scripts/render_lottie.py logo_animation.json preview.gif --preview-frames 60\n\n# Alternative: Test render mode (200x200, 15fps with confirmation prompt)\npython scripts/render_lottie.py logo_animation.json logo.gif --test-render\n\n# If preview looks good â†’ Render full animation\npython scripts/render_lottie.py logo_animation.json logo.gif\n\n# Optional: MP4 export (better compression than GIF)\npython scripts/render_lottie.py logo_animation.json logo.mp4\n\n# Optional: Batch export all formats\npython scripts/batch_export.py logo_animation.json ./output gif,mp4,json\n```\n\n**Important notes:**\n- Assets are resolved **relative to the Lottie JSON file location** (not current working directory)\n- Asset validation runs automatically before rendering\n- Output verification detects blank/corrupted files\n- Use `--preview-frames N` to render only first N frames for quick validation\n\n---\n\n### 7. Optional: Embed for Distribution\n\n**After successful rendering**, optionally convert to embedded base64 for standalone distribution:\n\n```json\n// Replace external reference with base64 from logo_base64.txt\n\"assets\": [{\"id\": \"logo_image\", \"p\": \"data:image/png;base64,...\", \"e\": 1}]\n```\n\n**Note:** Keep external version for future edits/rendering!\n\n---\n\n## Animation Philosophy\n\n### The Two-Phase Approach\n\n**Phase 1: Define Philosophy** (think before implementing)\n\n1. What personality does this brand have?\n2. What emotion should the animation evoke?\n3. What motion metaphor fits?\n\n**Phase 2: Express Through Technical Choices**\n\n- **Choose properties** that express philosophy (position/scale/rotation/opacity)\n- **Select easing** that matches personality (ease-out=confident, bounce=playful)\n- **Set timing** that aligns with emotion (fast=energetic, slow=elegant)\n\n### Philosophy Examples\n\n**\"Confident Professionalism\"**\n- Philosophy: Trustworthy, established, competent\n- Expression: Slow ease-out fade (0â†’100% opacity) + gentle scale (95%â†’100%)\n- Timing: 2s duration, no overshoot\n- Example: [references/real-world-examples/slack-hover-pinch.json](references/real-world-examples/slack-hover-pinch.json)\n\n**\"Playful Energy\"**\n- Philosophy: Fun, approachable, memorable\n- Expression: Bounce entrance with overshoot\n- Timing: 1s duration, back easing (0.6/-0.28)\n- Example: [references/real-world-examples/reddit-hover-pinch.json](references/real-world-examples/reddit-hover-pinch.json)\n\n**\"Audio/Speech Brand\"**\n- Philosophy: Sound, rhythm, waveforms, dynamic\n- Expression: Vertical waveform with dense keyframes (30-45 keyframes, 60fps)\n- Timing: 3s loop, organic easing (0.25/0.75)\n- **Critical:** See \"Organic/Continuous Motion\" in Motion Types section below\n\nMore examples in [references/preset_library.md](references/preset_library.md) and [references/animation_theory.md](references/animation_theory.md).\n\n---\n\n## Motion Type Quick Reference\n\nChoose motion type based on brand personality:\n\n### Static/Corporate Motion\nProfessional brands (B2B, finance, legal)\n\n**Parameters:**\n- Keyframes: 8-12 (sparse, deliberate)\n- Easing: `0.42/0.58` (standard ease-in-out)\n- FPS: 30\n- Duration: 1.5-2s\n\n**Use for:** Corporate logos, B2B brands, professional presentations\n\n---\n\n### Organic/Continuous Motion\nAudio, music, speech AI, nature brands\n\n**Parameters:**\n- Keyframes: 25-45 â† **Critical for smoothness**\n- Easing: `0.25/0.75` (softer, more organic)\n- FPS: 60 â† **Essential for fluidity**\n- Duration: 3s\n\n**Use for:** Audio apps, music platforms, speech AI, organic products\n\n**Example:** Vertical bar waveform pattern in [references/detailed_examples.md](references/detailed_examples.md#7-vertical-bar-waveform-organic-motion)\n\n---\n\n### Bold/Attention-Grabbing\nStartups, social media, marketing\n\n**Parameters:**\n- Keyframes: 15-25\n- Easing: `0.34/1.56` (playful bounce) or `0.6/-0.28` (back overshoot)\n- FPS: 60\n- Duration: 0.8-1.5s\n\n**Use for:** Startup logos, social media intros, marketing campaigns\n\n---\n\n### Cinematic/Complex\nPremium brands, film production\n\n**Parameters:**\n- Keyframes: 50-120\n- Easing: Custom bezier curves, variable timing\n- FPS: 60-120\n- Duration: 3-5s\n\n**Use for:** Luxury brands, film intros, high-end agency work\n\n---\n\n## Animation Pattern Quick Reference\n\n### Single-Element Patterns\n\n| Pattern | Duration | Properties | Use Case |\n|---------|----------|------------|----------|\n| **Fade + Gentle Scale** | 1.5s | Opacity: 0â†’100%, Scale: 95â†’100% | Corporate entrances |\n| **Bounce Entrance** | 1.2s | Position, Scale, Opacity | Energetic brands |\n| **Scale Pulse** | 3s loop | Scale: 100â†’103â†’100% | Idle states, CTAs |\n| **Smooth Rotation** | 10s loop | Rotation: 0â†’360Â° | Loading, tech logos |\n| **Wiggle/Jello** | 0.8s | Rotation: Â±5Â° oscillation | Playful notifications |\n\n**Full code examples:** [references/detailed_examples.md](references/detailed_examples.md)\n\n---\n\n### Multi-Element Coordination\n\n**Pattern 1: Simultaneous Entrance**\nBoth elements appear together (cohesive brand)\n\n```json\nIcon: {\"t\": 0, \"s\": [0]}, {\"t\": 60, \"s\": [100]}\nText: {\"t\": 0, \"s\": [0]}, {\"t\": 60, \"s\": [100]}\n// Both start at t:0 â†’ Synchronized\n```\n\n**Pattern 2: Staggered Entrance**\nIcon establishes first, text reinforces (storytelling)\n\n```json\nIcon: {\"t\": 0, \"s\": [0]}, {\"t\": 45, \"s\": [100]}\nText: {\"t\": 30, \"s\": [0]}, {\"t\": 75, \"s\": [100]}\n// Text delayed 30 frames (0.5s at 60fps)\n```\n\n**Timing guidelines:**\n- 15 frames (0.25s): Subtle stagger\n- 30 frames (0.5s): Noticeable sequence â† Most common\n- 45 frames (0.75s): Dramatic two-act reveal\n\n**Full patterns:** [references/detailed_examples.md#multi-element-coordination](references/detailed_examples.md#multi-element-coordination)\n\n---\n\n## User Intent Classification\n\nAlways classify user intent to select appropriate animation style:\n\n| Intent | Keyframes | Easing | FPS | Duration | Motion |\n|--------|-----------|--------|-----|----------|--------|\n| **Subtle/Professional** | 8-12 | 0.42/0.58 | 30 | 1.5-2s | Slow, controlled, minimal rotation |\n| **Bold/Attention** | 15-25 | 0.34/1.56 | 60 | 0.8-1.5s | Medium-fast, dynamic, Â±10-20% scale |\n| **Playful/Creative** | 12-20 | 0.34/1.56 | 30-60 | 1-2s | Bouncy, exaggerated, wiggle effects |\n| **Organic/Continuous** | 25-45 | 0.25/0.75 | 60 | 3s | Waveforms, pulses, flowing rhythms |\n\n**Default:** Provide animation rather than asking questions, unless user explicitly requests options.\n\n---\n\n## Known Limitations\n\n### Asset Path Resolution\n\n**Current behavior:**\n- External assets (PNGs/SVGs) are resolved **relative to the Lottie JSON file location**\n- The renderer changes the working directory to the JSON file's directory during rendering\n- Asset validation runs automatically before rendering begins\n\n**Example:**\n```\nproject/\nâ”œâ”€â”€ animations/\nâ”‚   â””â”€â”€ logo_animation.json  (references \"logo_optimized.png\")\nâ””â”€â”€ logo_optimized.png\n\n# This will FAIL - asset not found\n```\n\n**Solution:** Place assets in the same directory as the JSON file:\n```\nproject/animations/\nâ”œâ”€â”€ logo_animation.json\nâ””â”€â”€ logo_optimized.png  # âœ… Correct location\n```\n\n### Embedded Base64 vs External References\n\n**Embedded base64** (`\"e\": 1`):\n- **Pros:** Standalone file, easy distribution\n- **Cons:** Cairo MemoryError for images >100KB, larger file sizes, not editable\n\n**External references** (`\"e\": 0`):\n- **Pros:** No memory issues, smaller JSON files, easy to update assets\n- **Cons:** Requires keeping asset files alongside JSON\n\n**Recommended workflow:**\n1. Use external references during development/rendering\n2. Optionally embed base64 AFTER successful rendering for distribution\n3. Keep external version for future edits\n\n---\n\n## Critical Warnings\n\n### âŒ Common Mistakes to Avoid\n\n1. **Creating animation before defining philosophy** â†’ Random trial-and-error wastes 15-30 minutes\n2. **Using PIL ImageDraw to recreate logo text** â†’ Creates DIFFERENT text, not your logo text\n3. **Embedding base64 before rendering** â†’ Cairo MemoryError crash (images >100KB)\n4. **Using 1000px for small elements** â†’ Huge files (400KB+), memory issues\n5. **Skipping logo analysis** â†’ Wrong workflow, have to restart\n6. **Forgetting loop validation** â†’ Visible jump when animation loops\n7. **Skipping preview renders** â†’ Waste time on full renders before validating concept\n8. **Rendering full SVG then cropping** â†’ Fuzzy edges, massive file sizes\n\n**Full list with code examples:** [references/anti_patterns.md](references/anti_patterns.md)\n\n---\n\n### âš ï¸ Text in Logos - CRITICAL\n\n**If logo contains text**, you MUST follow specialized workflow:\n\n1. **Extract text from logo SVG** (do NOT recreate with PIL ImageDraw)\n2. **Choose appropriate text animation method** (fade/stroke/transform)\n3. **Implement proper synchronization** with other elements\n\n**See:** [references/text_animation_guide.md](references/text_animation_guide.md) for complete guide\n\n---\n\n### âš ï¸ External References Required\n\n**Always use external file references during development/rendering:**\n\n```json\n// âœ… CORRECT: External reference\n\"assets\": [{\"id\": \"logo\", \"p\": \"logo_optimized.png\", \"e\": 0}]\n\n// âŒ WRONG: Embedded base64 (causes Cairo crash if >100KB)\n\"assets\": [{\"id\": \"logo\", \"p\": \"data:image/png;base64,...\", \"e\": 1}]\n```\n\n**Why:** Cairo renderer crashes with embedded images >100KB. Use external during development, optionally embed AFTER successful rendering.\n\n---\n\n## Helper Scripts Quick Reference\n\n| Script | Purpose | Example |\n|--------|---------|---------|\n| `prepare_logo.py` | Optimize and convert logo images | `python scripts/prepare_logo.py logo.png --max-size 500` |\n| `extract_svg_elements.py` | Extract elements from SVG | `python scripts/extract_svg_elements.py logo.svg --list` |\n| `validate_lottie.py` | Check Lottie structure | `python scripts/validate_lottie.py animation.json` |\n| `validate_loop.py` | Verify perfect loop | `python scripts/validate_loop.py animation.json` |\n| `render_lottie.py` | Render to GIF/MP4 (with asset validation) | `python scripts/render_lottie.py animation.json output.gif` |\n| `render_lottie.py --preview-frames N` | Quick preview (first N frames) | `python scripts/render_lottie.py animation.json preview.gif --preview-frames 60` |\n| `render_lottie.py --test-render` | Test mode with size warnings | `python scripts/render_lottie.py animation.json test.gif --test-render` |\n| `batch_export.py` | Export multiple formats | `python scripts/batch_export.py animation.json ./output gif,mp4` |\n\n**New features in render_lottie.py:**\n- âœ… Automatic asset validation (checks for missing external files)\n- âœ… Asset path resolution (relative to JSON file location)\n- âœ… Output verification (detects blank/corrupted files)\n- âœ… Preview mode (`--preview-frames N`) - renders only first N frames\n- âœ… Test mode (`--test-render`) - small test render with confirmation prompt\n\n**Detailed usage:** [references/script_usage.md](references/script_usage.md)\n\n---\n\n## Lottie JSON Fundamentals\n\n### Basic Structure\n\n```json\n{\n  \"v\": \"5.7.4\",           // Lottie version\n  \"fr\": 60,               // Frame rate\n  \"ip\": 0,                // In point (start frame)\n  \"op\": 180,              // Out point (end frame)\n  \"w\": 800,               // Width\n  \"h\": 800,               // Height\n  \"layers\": [...],        // Animation layers\n  \"assets\": [...]         // Image/asset references\n}\n```\n\n### Layer Types\n\n- **Type 2 (Image Layer):** Most common - animates PNG/SVG images\n- **Type 4 (Shape Layer):** Programmatic geometry (circles, rectangles, paths)\n\n### Animated Properties\n\n- **`o`:** Opacity (0-100)\n- **`p`:** Position [x, y]\n- **`s`:** Scale [x%, y%]\n- **`r`:** Rotation (degrees)\n- **`a`:** Anchor point [x, y]\n\n### Keyframe Structure\n\n```json\n\"o\": {\n  \"a\": 1,  // Animated (1) or static (0)\n  \"k\": [\n    {\"t\": 0, \"s\": [0], \"e\": [100], \"i\": {...}, \"o\": {...}},\n    {\"t\": 60, \"s\": [100]}\n  ]\n}\n```\n\n- **`t`:** Time (frame number)\n- **`s`:** Start value\n- **`e`:** End value\n- **`i`:** In tangent (ease in)\n- **`o`:** Out tangent (ease out)\n\n**Complete specification:** [references/lottie_spec.md](references/lottie_spec.md)\n\n---\n\n## Easing Functions\n\n**Never use linear easing** - always use curves for professional motion.\n\n| Easing | Values | Feel | Use Case |\n|--------|--------|------|----------|\n| **Ease-in-out (standard)** | `0.42/0.58` | Balanced, professional | Corporate, general use |\n| **Organic** | `0.25/0.75` | Soft, natural | Audio brands, waveforms, continuous motion |\n| **Bounce** | `0.34/1.56` | Playful, energetic | Startups, playful brands |\n| **Back** | `0.6/-0.28` & `0.735/0.045` | Overshoot, dynamic | Bold marketing, attention-grabbing |\n\n**Theory and examples:** [references/animation_theory.md](references/animation_theory.md)\n\n---\n\n## Dependencies\n\n### Required\n```bash\npip install lottie[all]    # Lottie manipulation\npip install Pillow         # Image processing\npip install pycairo        # Cairo rendering (for GIF)\n```\n\n### Cairo Installation\n\n**macOS:**\n```bash\nbrew install cairo pkg-config\npip install pycairo\n```\n\n**Linux (Ubuntu/Debian):**\n```bash\nsudo apt-get install libcairo2-dev pkg-config python3-dev\npip install pycairo\n```\n\n**Verify:**\n```bash\npython3 -c \"import cairo; print('Cairo OK')\"\n```\n\n**Troubleshooting:** [references/troubleshooting.md#cairo-and-dependencies](references/troubleshooting.md#cairo-and-dependencies)\n\n---\n\n## Troubleshooting\n\n### Quick Fixes\n\n**Asset not found errors:**\n- **Cause:** Assets not in same directory as Lottie JSON\n- **Fix:** Move assets to JSON file's directory, or use absolute paths\n- **Validation:** Run `render_lottie.py` - it validates assets before rendering\n\n**Blank/corrupted output:**\n- **Cause:** Missing assets, wrong paths, or rendering errors\n- **Fix:** Check asset validation messages, verify file sizes (output <1KB indicates failure)\n- **Detection:** Output verification runs automatically after rendering\n\n**MemoryError during GIF rendering:**\n- **Cause:** Embedded base64 images >100KB\n- **Fix:** Use external reference (`\"e\": 0`) instead\n\n**Loop has visible jump:**\n- **Cause:** Last keyframe doesn't match first\n- **Fix:** Run `validate_loop.py` and ensure last frame = first frame\n\n**Text looks wrong:**\n- **Cause:** Used PIL ImageDraw to recreate text\n- **Fix:** Extract text from logo SVG with `extract_svg_elements.py`\n\n**Animation too choppy:**\n- **Cause:** Too few keyframes or wrong FPS\n- **Fix:** Add keyframes (25-45 for organic motion), use 60fps for continuous motion\n\n**Preview renders save time:**\n- **Tip:** Use `--preview-frames 60` to validate concept before full render\n- **Tip:** Use `--test-render` for interactive testing with size warnings\n\n**Comprehensive guide:** [references/troubleshooting.md](references/troubleshooting.md)\n\n---\n\n## Advanced References\n\n### Detailed Documentation\n\n- **[references/detailed_examples.md](references/detailed_examples.md)** - Full Lottie JSON code for all patterns\n- **[references/animation_theory.md](references/animation_theory.md)** - Motion design principles and easing theory\n- **[references/preset_library.md](references/preset_library.md)** - Complete preset collection with real-world examples\n- **[references/lottie_spec.md](references/lottie_spec.md)** - Lottie JSON specification details\n- **[references/script_usage.md](references/script_usage.md)** - Complete script documentation\n- **[references/text_animation_guide.md](references/text_animation_guide.md)** - Specialized text animation workflows\n- **[references/anti_patterns.md](references/anti_patterns.md)** - Common mistakes with full code examples\n- **[references/troubleshooting.md](references/troubleshooting.md)** - Comprehensive troubleshooting guide\n- **[references/real-world-examples/](references/real-world-examples/)** - Production animations from major brands\n\n---\n\n## File Size Guidelines\n\n**Target sizes for different use cases:**\n\n| Use Case | Lottie JSON | GIF | MP4 | Image Assets |\n|----------|-------------|-----|-----|--------------|\n| Email signature | 20-50KB | 500KB-1MB | 200-500KB | <30KB each |\n| Website hero | 30-80KB | 1-3MB | 500KB-1.5MB | <50KB each |\n| Social media | 50-150KB | 3-8MB | 1-3MB | <80KB each |\n| Splash screen | 30-100KB | 2-5MB | 800KB-2MB | <60KB each |\n\n**Optimization:** Use `scripts/optimize_lottie.py` to reduce file sizes by removing redundant keyframes and rounding values.\n\n---\n\n## Curated Presets\n\nQuick reference to common presets (full code in [references/preset_library.md](references/preset_library.md)):\n\n**Branding Styles:**\n- Corporate Subtle - Fade + gentle scale (1.5s)\n- Startup Energetic - Bounce + overshoot (1.2s)\n- Luxury Elegant - Slow fade + minimal scale (3s)\n- Tech Glitch - Digital disruption effect (1s)\n\n**Use Cases:**\n- Website Hero - Quick professional entrance (0.8s)\n- Email Signature - Subtle loop (3s)\n- Social Media Intro - Bold entrance (2s)\n- Splash Screen - Brand moment with exit (2.5s)\n\n**Real-World Examples:**\nStudy hover animations from major brands in [references/real-world-examples/](references/real-world-examples/):\n- Reddit - Playful elastic bounce\n- Slack - Professional restrained pinch\n- Medium - Gentle editorial fade\n- Flickr - Camera shutter effect\n- Discord - Character wink\n\n---\n\n## Quick Decision Checklist\n\nBefore creating animation, verify:\n\n- [ ] Defined motion philosophy (personality + emotion + metaphor)\n- [ ] Analyzed logo structure (text? multi-element? SVG or PNG?)\n- [ ] Chose correct workflow based on analysis\n- [ ] If text present: Read [references/text_animation_guide.md](references/text_animation_guide.md)\n- [ ] Using external references (`\"e\": 0`) during development\n- [ ] Element sizes appropriate (500px full logo, 100-250px elements)\n- [ ] Selected motion type (Static/Organic/Bold/Cinematic)\n- [ ] Chosen timing strategy (simultaneous vs staggered)\n- [ ] Will validate with preview render before full render\n- [ ] Will run `validate_loop.py` if creating loop\n\n**If all checked â†’ Proceed with confidence âœ…**\n\n---\n\n## Tips for Success\n\n1. **Philosophy first** - 30 seconds planning saves 15-30 minutes iteration\n2. **Analyze before animating** - Understand logo structure upfront\n3. **Preview early, preview often** - Test 30-60 frame versions before full render\n4. **External references during development** - Embed base64 only after successful rendering\n5. **Match motion to brand** - Corporate â‰  startup â‰  audio brand\n6. **Perfect loops matter** - Use `validate_loop.py` to verify\n7. **Size elements appropriately** - 100-250px for elements, not 1000px\n8. **Extract, don't recreate** - Never use PIL to recreate logo text\n9. **Validate before rendering** - Run `validate_lottie.py` and `validate_loop.py`\n10. **Read references when stuck** - Detailed docs available for every topic\n\n---\n\n**Remember:** The goal is creating motion that enhances brand identity, not random animation. Philosophy-first workflow ensures alignment from the start."
    },
    "marketplace": {
      "hasMarketplaceJson": false
    },
    "internal": {
      "syncedAt": "2026-01-08T00:26:04.960Z",
      "version": 1
    }
  },
  "bayramannakov-claude-reflect": {
    "id": "bayramannakov-claude-reflect",
    "name": "claude-reflect",
    "description": "Self-learning system that captures corrections during sessions and reminds users to run /reflect to update CLAUDE.md. Use when discussing learnings, corrections, or when the user mentions remembering something for future sessions.",
    "repo": {
      "owner": "BayramAnnakov",
      "name": "claude-reflect",
      "fullName": "BayramAnnakov/claude-reflect",
      "url": "https://github.com/BayramAnnakov/claude-reflect",
      "defaultBranch": "main"
    },
    "metadata": {
      "stars": 265,
      "forks": 12,
      "language": "Python",
      "topics": [
        "claude-code",
        "claude-skills",
        "memory",
        "productivity",
        "self-learning"
      ],
      "createdAt": "2026-01-03T20:51:36Z",
      "updatedAt": "2026-01-07T23:46:34Z",
      "pushedAt": "2026-01-07T06:18:02Z",
      "license": "MIT License"
    },
    "category": "tools",
    "tags": [
      "claude-code",
      "claude-skills",
      "memory",
      "productivity",
      "self-learning",
      "corrections",
      "sessions",
      "when",
      "self",
      "learning"
    ],
    "skillMd": {
      "raw": "---\nname: claude-reflect\ndescription: Self-learning system that captures corrections during sessions and reminds users to run /reflect to update CLAUDE.md. Use when discussing learnings, corrections, or when the user mentions remembering something for future sessions.\n---\n\n# Claude Reflect - Self-Learning System\n\nA two-stage system that helps Claude Code learn from user corrections.\n\n## How It Works\n\n**Stage 1: Capture (Automatic)**\nHooks detect correction patterns (\"no, use X\", \"actually...\", \"use X not Y\") and queue them to `~/.claude/learnings-queue.json`.\n\n**Stage 2: Process (Manual)**\nUser runs `/reflect` to review and apply queued learnings to CLAUDE.md files.\n\n## Available Commands\n\n| Command | Purpose |\n|---------|---------|\n| `/reflect` | Process queued learnings with human review |\n| `/reflect --scan-history` | Scan past sessions for missed learnings |\n| `/reflect --dry-run` | Preview changes without applying |\n| `/skip-reflect` | Discard all queued learnings |\n| `/view-queue` | View pending learnings without processing |\n\n## When to Remind Users\n\nRemind users about `/reflect` when:\n- They complete a feature or meaningful work unit\n- They make corrections you should remember for future sessions\n- They explicitly say \"remember this\" or similar\n- Context is about to compact and queue has items\n\n## Correction Detection Patterns\n\nHigh-confidence corrections:\n- Tool rejections (user stops an action with guidance)\n- \"no, use X\" / \"don't use Y\"\n- \"actually...\" / \"I meant...\"\n- \"use X not Y\" / \"X instead of Y\"\n- \"remember:\" (explicit marker)\n\n## CLAUDE.md Destinations\n\n- `~/.claude/CLAUDE.md` - Global learnings (model names, general patterns)\n- `./CLAUDE.md` - Project-specific learnings (conventions, tools, structure)\n\n## Example Interaction\n\n```\nUser: no, use gpt-5.1 not gpt-5 for reasoning tasks\nClaude: Got it, I'll use gpt-5.1 for reasoning tasks.\n\n[Hook captures this correction to queue]\n\nUser: /reflect\nClaude: Found 1 learning queued. \"Use gpt-5.1 for reasoning tasks\"\n        Scope: global\n        Apply to ~/.claude/CLAUDE.md? [y/n]\n```\n",
      "frontmatter": {
        "name": "claude-reflect",
        "description": "Self-learning system that captures corrections during sessions and reminds users to run /reflect to update CLAUDE.md. Use when discussing learnings, corrections, or when the user mentions remembering something for future sessions."
      },
      "content": "# Claude Reflect - Self-Learning System\n\nA two-stage system that helps Claude Code learn from user corrections.\n\n## How It Works\n\n**Stage 1: Capture (Automatic)**\nHooks detect correction patterns (\"no, use X\", \"actually...\", \"use X not Y\") and queue them to `~/.claude/learnings-queue.json`.\n\n**Stage 2: Process (Manual)**\nUser runs `/reflect` to review and apply queued learnings to CLAUDE.md files.\n\n## Available Commands\n\n| Command | Purpose |\n|---------|---------|\n| `/reflect` | Process queued learnings with human review |\n| `/reflect --scan-history` | Scan past sessions for missed learnings |\n| `/reflect --dry-run` | Preview changes without applying |\n| `/skip-reflect` | Discard all queued learnings |\n| `/view-queue` | View pending learnings without processing |\n\n## When to Remind Users\n\nRemind users about `/reflect` when:\n- They complete a feature or meaningful work unit\n- They make corrections you should remember for future sessions\n- They explicitly say \"remember this\" or similar\n- Context is about to compact and queue has items\n\n## Correction Detection Patterns\n\nHigh-confidence corrections:\n- Tool rejections (user stops an action with guidance)\n- \"no, use X\" / \"don't use Y\"\n- \"actually...\" / \"I meant...\"\n- \"use X not Y\" / \"X instead of Y\"\n- \"remember:\" (explicit marker)\n\n## CLAUDE.md Destinations\n\n- `~/.claude/CLAUDE.md` - Global learnings (model names, general patterns)\n- `./CLAUDE.md` - Project-specific learnings (conventions, tools, structure)\n\n## Example Interaction\n\n```\nUser: no, use gpt-5.1 not gpt-5 for reasoning tasks\nClaude: Got it, I'll use gpt-5.1 for reasoning tasks.\n\n[Hook captures this correction to queue]\n\nUser: /reflect\nClaude: Found 1 learning queued. \"Use gpt-5.1 for reasoning tasks\"\n        Scope: global\n        Apply to ~/.claude/CLAUDE.md? [y/n]\n```"
    },
    "marketplace": {
      "hasMarketplaceJson": false
    },
    "internal": {
      "syncedAt": "2026-01-08T00:30:10.789Z",
      "version": 1
    }
  },
  "ait88-claude-workflow-toolkit": {
    "id": "ait88-claude-workflow-toolkit",
    "name": "claude-workflow-toolkit",
    "description": "Reusable workflow optimization toolkit for Claude Code agents.",
    "repo": {
      "owner": "ait88",
      "name": "claude-workflow-toolkit",
      "fullName": "ait88/claude-workflow-toolkit",
      "url": "https://github.com/ait88/claude-workflow-toolkit",
      "defaultBranch": "master"
    },
    "metadata": {
      "stars": 1,
      "forks": 1,
      "language": "Shell",
      "topics": [
        "agentic-workflow",
        "claude-code",
        "claude-skills",
        "gh-cli",
        "token-optimization"
      ],
      "createdAt": "2026-01-06T10:15:03Z",
      "updatedAt": "2026-01-07T02:14:55Z",
      "pushedAt": "2026-01-07T02:13:53Z",
      "license": "MIT License"
    },
    "category": "tools",
    "tags": [
      "agentic-workflow",
      "claude-code",
      "claude-skills",
      "gh-cli",
      "token-optimization",
      "reusable",
      "workflow",
      "optimization",
      "toolkit",
      "claude"
    ],
    "skillMd": {
      "raw": "# Claude Workflow Toolkit\n\n## Purpose\n\nThis toolkit provides templates and patterns for optimizing Claude Code agent workflows in any repository. Use it to apply consistent, efficient workflow automation to a target project.\n\n## When to Use This Toolkit\n\nUse this toolkit when:\n- Setting up a new project for Claude Code agent collaboration\n- Optimizing an existing project's agent workflow\n- Updating a project to latest workflow best practices\n\n## How to Apply This Toolkit\n\n### Step 1: Understand the Target Project\n\nBefore applying, gather information about the target project:\n- **Language/Framework**: What tech stack? (PHP, Node, Python, Bash, etc.)\n- **Package Manager**: composer, npm, pip, none?\n- **Test Command**: How are tests run?\n- **Lint Command**: How is code style checked?\n- **Branch Naming**: Any existing conventions?\n- **Label Scheme**: Existing GitHub labels?\n- **Directory Structure**: Where does source code live?\n\n### Step 2: Select a Profile\n\nChoose the closest matching profile from `/profiles/`:\n- `default.yaml` - Generic, works for any project\n- `php-composer.yaml` - PHP projects using Composer\n- `bash-cli.yaml` - Bash CLI tools and scripts\n- `node-npm.yaml` - Node.js/TypeScript projects\n- `python-poetry.yaml` - Python projects\n\n### Step 3: Customize Variables\n\nEach template uses `{{VARIABLE}}` placeholders. Common variables:\n\n| Variable | Description | Example |\n|----------|-------------|---------|\n| `{{PROJECT_NAME}}` | Repository name | `my-project` |\n| `{{REPO_OWNER}}` | GitHub owner/org | `username` |\n| `{{DEFAULT_BRANCH}}` | Main branch name | `main` |\n| `{{TEST_COMMAND}}` | How to run tests | `composer test` |\n| `{{LINT_COMMAND}}` | How to check style | `npm run lint` |\n| `{{PHASE_PREFIX}}` | Label prefix for phases | `phase-` |\n| `{{PHASE_COUNT}}` | Number of phases (0-indexed) | `6` |\n| `{{SKILLS_DIR}}` | Where skills live | `.claude/skills` |\n| `{{DOCS_DIR}}` | Documentation directory | `docs` |\n\n### Step 4: Generate Files\n\nFor each template:\n1. Read the template file\n2. Replace all `{{VARIABLE}}` placeholders with project-specific values\n3. Write to the target project location\n4. Make skill scripts executable (`chmod +x`)\n\n### Step 5: Verify Installation\n\nAfter applying:\n1. Verify skills are executable: `ls -la {{SKILLS_DIR}}/`\n2. Test claim-issue with a test issue number\n3. Run check-workflow to verify it detects current state\n4. Review generated documentation for accuracy\n\n## Template Reference\n\n### Skills Templates\n\n#### `claim-issue.sh.template`\nAtomically claims a GitHub issue and creates a feature branch.\n- Removes `agent-ready` label\n- Adds `in-progress` label\n- Creates branch: `<issue>-<title-slug>`\n- Single operation prevents inconsistent state\n\n#### `check-workflow.sh.template`\nValidates current workflow state using GraphQL (1 API call vs 4-5 REST calls).\n- Extracts issue number from branch name\n- Validates labels match workflow stage\n- Provides fix commands for any issues\n- Color-coded output for quick scanning\n\n#### `submit-pr.sh.template`\nCreates PR and updates labels atomically.\n- Pushes current branch\n- Creates PR with \"Closes #X\"\n- Removes `in-progress`, adds `needs-review`\n\n### Documentation Templates\n\n#### `QUICK-REFERENCE.md.template`\nFast navigation document for agents - \"where do I find X?\"\n- Quick start paths for common tasks\n- Pre-flight checklists\n- Coding conventions summary\n- Links to detailed docs\n\n#### `FAQ-AGENTS.md.template`\nPre-answered common questions to reduce repeated lookups.\n- Project-specific Q&A format\n- Reduces tokens spent re-discovering information\n\n#### `CODEBASE-MAP.md.template`\nVisual directory structure with annotations.\n- What each directory/file does\n- Entry points for common tasks\n- Dependency relationships\n\n## Optimization Principles\n\nThese skills are designed around key principles:\n\n1. **Minimize API Calls**: GraphQL over REST where possible\n2. **Atomic Operations**: Prevent inconsistent state\n3. **Self-Documenting**: Skills output what they're doing\n4. **Graceful Errors**: Clear messages, actionable fixes\n5. **Idempotent Where Possible**: Safe to re-run\n\n## Application Workflow\n\nWhen applying this toolkit to a target project:\n\n```\n1. Clone/access target project\n2. Gather project information (language, test command, etc.)\n3. Select appropriate profile\n4. For each template:\n   a. Read template content\n   b. Substitute {{VARIABLES}} with project values\n   c. Write to target path\n   d. Set permissions (chmod +x for scripts)\n5. Update target project's .gitignore if needed\n6. Test the generated skills\n7. Commit changes to target project\n```\n\n## Output Structure\n\nAfter applying, the target project will have:\n\n```\ntarget-project/\nâ”œâ”€â”€ .claude/\nâ”‚   â”œâ”€â”€ skills/\nâ”‚   â”‚   â”œâ”€â”€ claim-issue      # Claim issue + create branch\nâ”‚   â”‚   â”œâ”€â”€ check-workflow   # Validate workflow state\nâ”‚   â”‚   â”œâ”€â”€ submit-pr        # Create PR + update labels\nâ”‚   â”‚   â””â”€â”€ README.md        # Skills documentation\nâ”‚   â””â”€â”€ settings.local.json  # Pre-configured Claude Code permissions\nâ””â”€â”€ {{DOCS_DIR}}/\n    â”œâ”€â”€ QUICK-REFERENCE.md   # Navigation hub\n    â”œâ”€â”€ FAQ-AGENTS.md        # Pre-answered questions\n    â””â”€â”€ CODEBASE-MAP.md      # Annotated directory structure\n```\n\n### Optional: Setup GitHub Labels\n\nBefore using the workflow, the target repository needs the required labels. Run the setup script from this toolkit in the target repo:\n\n```bash\n# From target project directory\n/path/to/claude-workflow-toolkit/scripts/setup-labels.sh\n```\n\nThis creates: `agent-ready`, `in-progress`, `needs-review`, `blocked`, `phase-0` through `phase-6`, and type labels.\n\n## Maintenance\n\nWhen updating the toolkit:\n1. Update templates in this repo\n2. For projects using this toolkit, re-run the application process\n3. Projects can diff changes and selectively adopt updates\n\n## Troubleshooting\n\n### \"Permission denied\" when running skills\n```bash\nchmod +x {{SKILLS_DIR}}/*\n```\n\n### \"gh: command not found\"\nInstall GitHub CLI: https://cli.github.com/\n\n### \"jq: command not found\"\nInstall jq:\n- macOS: `brew install jq`\n- Ubuntu/Debian: `sudo apt-get install jq`\n- RHEL/CentOS: `sudo yum install jq`\n\n### Skills not appearing as slash commands\nSkills should be in `{{SKILLS_DIR}}/` directory. Verify:\n1. Files exist and are executable\n2. Files have no `.sh` extension (just `claim-issue`, not `claim-issue.sh`)\n3. Claude Code is restarted after adding skills\n\n### SSH authentication fails\nThe skill templates include automatic SSH/HTTPS fallback. If SSH fails, they'll attempt to use `gh auth setup-git` to configure HTTPS authentication. Ensure:\n1. GitHub CLI is authenticated: `gh auth status`\n2. If using SSH, keys are properly configured: `ssh -T git@github.com`\n",
      "frontmatter": {},
      "content": "# Claude Workflow Toolkit\n\n## Purpose\n\nThis toolkit provides templates and patterns for optimizing Claude Code agent workflows in any repository. Use it to apply consistent, efficient workflow automation to a target project.\n\n## When to Use This Toolkit\n\nUse this toolkit when:\n- Setting up a new project for Claude Code agent collaboration\n- Optimizing an existing project's agent workflow\n- Updating a project to latest workflow best practices\n\n## How to Apply This Toolkit\n\n### Step 1: Understand the Target Project\n\nBefore applying, gather information about the target project:\n- **Language/Framework**: What tech stack? (PHP, Node, Python, Bash, etc.)\n- **Package Manager**: composer, npm, pip, none?\n- **Test Command**: How are tests run?\n- **Lint Command**: How is code style checked?\n- **Branch Naming**: Any existing conventions?\n- **Label Scheme**: Existing GitHub labels?\n- **Directory Structure**: Where does source code live?\n\n### Step 2: Select a Profile\n\nChoose the closest matching profile from `/profiles/`:\n- `default.yaml` - Generic, works for any project\n- `php-composer.yaml` - PHP projects using Composer\n- `bash-cli.yaml` - Bash CLI tools and scripts\n- `node-npm.yaml` - Node.js/TypeScript projects\n- `python-poetry.yaml` - Python projects\n\n### Step 3: Customize Variables\n\nEach template uses `{{VARIABLE}}` placeholders. Common variables:\n\n| Variable | Description | Example |\n|----------|-------------|---------|\n| `{{PROJECT_NAME}}` | Repository name | `my-project` |\n| `{{REPO_OWNER}}` | GitHub owner/org | `username` |\n| `{{DEFAULT_BRANCH}}` | Main branch name | `main` |\n| `{{TEST_COMMAND}}` | How to run tests | `composer test` |\n| `{{LINT_COMMAND}}` | How to check style | `npm run lint` |\n| `{{PHASE_PREFIX}}` | Label prefix for phases | `phase-` |\n| `{{PHASE_COUNT}}` | Number of phases (0-indexed) | `6` |\n| `{{SKILLS_DIR}}` | Where skills live | `.claude/skills` |\n| `{{DOCS_DIR}}` | Documentation directory | `docs` |\n\n### Step 4: Generate Files\n\nFor each template:\n1. Read the template file\n2. Replace all `{{VARIABLE}}` placeholders with project-specific values\n3. Write to the target project location\n4. Make skill scripts executable (`chmod +x`)\n\n### Step 5: Verify Installation\n\nAfter applying:\n1. Verify skills are executable: `ls -la {{SKILLS_DIR}}/`\n2. Test claim-issue with a test issue number\n3. Run check-workflow to verify it detects current state\n4. Review generated documentation for accuracy\n\n## Template Reference\n\n### Skills Templates\n\n#### `claim-issue.sh.template`\nAtomically claims a GitHub issue and creates a feature branch.\n- Removes `agent-ready` label\n- Adds `in-progress` label\n- Creates branch: `<issue>-<title-slug>`\n- Single operation prevents inconsistent state\n\n#### `check-workflow.sh.template`\nValidates current workflow state using GraphQL (1 API call vs 4-5 REST calls).\n- Extracts issue number from branch name\n- Validates labels match workflow stage\n- Provides fix commands for any issues\n- Color-coded output for quick scanning\n\n#### `submit-pr.sh.template`\nCreates PR and updates labels atomically.\n- Pushes current branch\n- Creates PR with \"Closes #X\"\n- Removes `in-progress`, adds `needs-review`\n\n### Documentation Templates\n\n#### `QUICK-REFERENCE.md.template`\nFast navigation document for agents - \"where do I find X?\"\n- Quick start paths for common tasks\n- Pre-flight checklists\n- Coding conventions summary\n- Links to detailed docs\n\n#### `FAQ-AGENTS.md.template`\nPre-answered common questions to reduce repeated lookups.\n- Project-specific Q&A format\n- Reduces tokens spent re-discovering information\n\n#### `CODEBASE-MAP.md.template`\nVisual directory structure with annotations.\n- What each directory/file does\n- Entry points for common tasks\n- Dependency relationships\n\n## Optimization Principles\n\nThese skills are designed around key principles:\n\n1. **Minimize API Calls**: GraphQL over REST where possible\n2. **Atomic Operations**: Prevent inconsistent state\n3. **Self-Documenting**: Skills output what they're doing\n4. **Graceful Errors**: Clear messages, actionable fixes\n5. **Idempotent Where Possible**: Safe to re-run\n\n## Application Workflow\n\nWhen applying this toolkit to a target project:\n\n```\n1. Clone/access target project\n2. Gather project information (language, test command, etc.)\n3. Select appropriate profile\n4. For each template:\n   a. Read template content\n   b. Substitute {{VARIABLES}} with project values\n   c. Write to target path\n   d. Set permissions (chmod +x for scripts)\n5. Update target project's .gitignore if needed\n6. Test the generated skills\n7. Commit changes to target project\n```\n\n## Output Structure\n\nAfter applying, the target project will have:\n\n```\ntarget-project/\nâ”œâ”€â”€ .claude/\nâ”‚   â”œâ”€â”€ skills/\nâ”‚   â”‚   â”œâ”€â”€ claim-issue      # Claim issue + create branch\nâ”‚   â”‚   â”œâ”€â”€ check-workflow   # Validate workflow state\nâ”‚   â”‚   â”œâ”€â”€ submit-pr        # Create PR + update labels\nâ”‚   â”‚   â””â”€â”€ README.md        # Skills documentation\nâ”‚   â””â”€â”€ settings.local.json  # Pre-configured Claude Code permissions\nâ””â”€â”€ {{DOCS_DIR}}/\n    â”œâ”€â”€ QUICK-REFERENCE.md   # Navigation hub\n    â”œâ”€â”€ FAQ-AGENTS.md        # Pre-answered questions\n    â””â”€â”€ CODEBASE-MAP.md      # Annotated directory structure\n```\n\n### Optional: Setup GitHub Labels\n\nBefore using the workflow, the target repository needs the required labels. Run the setup script from this toolkit in the target repo:\n\n```bash\n# From target project directory\n/path/to/claude-workflow-toolkit/scripts/setup-labels.sh\n```\n\nThis creates: `agent-ready`, `in-progress`, `needs-review`, `blocked`, `phase-0` through `phase-6`, and type labels.\n\n## Maintenance\n\nWhen updating the toolkit:\n1. Update templates in this repo\n2. For projects using this toolkit, re-run the application process\n3. Projects can diff changes and selectively adopt updates\n\n## Troubleshooting\n\n### \"Permission denied\" when running skills\n```bash\nchmod +x {{SKILLS_DIR}}/*\n```\n\n### \"gh: command not found\"\nInstall GitHub CLI: https://cli.github.com/\n\n### \"jq: command not found\"\nInstall jq:\n- macOS: `brew install jq`\n- Ubuntu/Debian: `sudo apt-get install jq`\n- RHEL/CentOS: `sudo yum install jq`\n\n### Skills not appearing as slash commands\nSkills should be in `{{SKILLS_DIR}}/` directory. Verify:\n1. Files exist and are executable\n2. Files have no `.sh` extension (just `claim-issue`, not `claim-issue.sh`)\n3. Claude Code is restarted after adding skills\n\n### SSH authentication fails\nThe skill templates include automatic SSH/HTTPS fallback. If SSH fails, they'll attempt to use `gh auth setup-git` to configure HTTPS authentication. Ensure:\n1. GitHub CLI is authenticated: `gh auth status`\n2. If using SSH, keys are properly configured: `ssh -T git@github.com`"
    },
    "marketplace": {
      "hasMarketplaceJson": false
    },
    "internal": {
      "syncedAt": "2026-01-08T00:30:44.239Z",
      "version": 1
    }
  },
  "santiago-afonso-codex-sandbox-preflight": {
    "id": "santiago-afonso-codex-sandbox-preflight",
    "name": "codex-sandbox-preflight",
    "description": "Use at the start of a Codex session (especially sandboxed) to run `scripts/codex-sandbox-preflight.sh` and interpret network + writable_roots constraints.",
    "repo": {
      "owner": "santiago-afonso",
      "name": "codex-sandbox-preflight",
      "fullName": "santiago-afonso/codex-sandbox-preflight",
      "url": "https://github.com/santiago-afonso/codex-sandbox-preflight",
      "defaultBranch": "main"
    },
    "metadata": {
      "stars": 0,
      "forks": 0,
      "language": "Shell",
      "topics": [
        "claude-skills",
        "codex",
        "skills"
      ],
      "createdAt": "2025-12-27T20:57:48Z",
      "updatedAt": "2026-01-06T15:04:26Z",
      "pushedAt": "2026-01-06T15:04:22Z"
    },
    "category": "development",
    "tags": [
      "claude-skills",
      "codex",
      "skills",
      "start",
      "session",
      "especially",
      "sandboxed"
    ],
    "skillMd": {
      "raw": "---\nname: codex-sandbox-preflight\ndescription: \"Use at the start of a Codex session (especially sandboxed) to run `scripts/codex-sandbox-preflight.sh` and interpret network + writable_roots constraints.\"\n---\n\n# Codex sandbox preflight\n\n## When to use\n- Start of a new Codex session (default).\n- You see sandbox-ish errors like `PermissionError: [Errno 1] Operation not permitted`, `seccomp`, or unexpected â€œPermission deniedâ€ when paths look writable.\n- You need to know if network is disabled in the tool sandbox before attempting auth, installs, `git push`, etc.\n\n## Workflow\n1) Run the preflight helper:\n```bash\nscripts/codex-sandbox-preflight.sh\n```\n\n2) If youâ€™re in a normal shell and want to see what happens when network is enabled inside the sandbox:\n```bash\nscripts/codex-sandbox-preflight.sh --with-network\n```\n\n3) Summarize results (donâ€™t paste the full output unless asked):\n- Tool sandbox network: `socket()` allowed vs blocked (and DNS if allowed).\n- Writable roots: whether `~/.config/wbg-auth` is writable inside the sandbox.\n- Config drift: whether `~/.codex/config.toml` is symlinked to dotfiles or has diverged.\n\n## Interpretation cheatsheet\n- `INFO- socket() syscall blocked`:\n  - Tool sandbox has network disabled (expected in many sandboxed sessions).\n  - Avoid network-dependent commands/tools inside the sandbox.\n  - To allow sandbox network, start Codex with `-c sandbox_workspace_write.network_access=true` (still sandboxed, but with egress).\n- `WARN missing_writable_root=$HOME/.config/wbg-auth` (or similar) / sandbox write fails for `~/.config/wbg-auth`:\n  - `wbg-auth` will crash on startup due to log file creation.\n  - Fix by adding `~/.config/wbg-auth` to `sandbox_workspace_write.writable_roots` in `~/.codex/config.toml`.\n\n## Notes / pitfalls\n- Running this from inside an already-restricted tool sandbox cannot â€œproveâ€ that enabling network would work; outer seccomp will still block `socket()`. Use `--with-network` from a normal shell for that.\n- This helper must never print secrets; it only checks tool presence, config linkage, writability, and basic DNS.\n",
      "frontmatter": {
        "name": "codex-sandbox-preflight",
        "description": "Use at the start of a Codex session (especially sandboxed) to run `scripts/codex-sandbox-preflight.sh` and interpret network + writable_roots constraints."
      },
      "content": "# Codex sandbox preflight\n\n## When to use\n- Start of a new Codex session (default).\n- You see sandbox-ish errors like `PermissionError: [Errno 1] Operation not permitted`, `seccomp`, or unexpected â€œPermission deniedâ€ when paths look writable.\n- You need to know if network is disabled in the tool sandbox before attempting auth, installs, `git push`, etc.\n\n## Workflow\n1) Run the preflight helper:\n```bash\nscripts/codex-sandbox-preflight.sh\n```\n\n2) If youâ€™re in a normal shell and want to see what happens when network is enabled inside the sandbox:\n```bash\nscripts/codex-sandbox-preflight.sh --with-network\n```\n\n3) Summarize results (donâ€™t paste the full output unless asked):\n- Tool sandbox network: `socket()` allowed vs blocked (and DNS if allowed).\n- Writable roots: whether `~/.config/wbg-auth` is writable inside the sandbox.\n- Config drift: whether `~/.codex/config.toml` is symlinked to dotfiles or has diverged.\n\n## Interpretation cheatsheet\n- `INFO- socket() syscall blocked`:\n  - Tool sandbox has network disabled (expected in many sandboxed sessions).\n  - Avoid network-dependent commands/tools inside the sandbox.\n  - To allow sandbox network, start Codex with `-c sandbox_workspace_write.network_access=true` (still sandboxed, but with egress).\n- `WARN missing_writable_root=$HOME/.config/wbg-auth` (or similar) / sandbox write fails for `~/.config/wbg-auth`:\n  - `wbg-auth` will crash on startup due to log file creation.\n  - Fix by adding `~/.config/wbg-auth` to `sandbox_workspace_write.writable_roots` in `~/.codex/config.toml`.\n\n## Notes / pitfalls\n- Running this from inside an already-restricted tool sandbox cannot â€œproveâ€ that enabling network would work; outer seccomp will still block `socket()`. Use `--with-network` from a normal shell for that.\n- This helper must never print secrets; it only checks tool presence, config linkage, writability, and basic DNS."
    },
    "marketplace": {
      "hasMarketplaceJson": false
    },
    "internal": {
      "syncedAt": "2026-01-08T00:33:11.282Z",
      "version": 1
    }
  },
  "blacktop-ipsw-skill": {
    "id": "blacktop-ipsw-skill",
    "name": "ipsw",
    "description": "Apple firmware and binary reverse engineering with the ipsw CLI tool. Use when analyzing iOS/macOS binaries, disassembling functions in dyld_shared_cache, dumping Objective-C headers from private frameworks, downloading IPSWs or kernelcaches, extracting entitlements, analyzing Mach-O files, or researching Apple security. Triggers on requests involving Apple RE, iOS internals, kernel analysis, KEXT extraction, or vulnerability research on Apple platforms.",
    "repo": {
      "owner": "blacktop",
      "name": "ipsw-skill",
      "fullName": "blacktop/ipsw-skill",
      "url": "https://github.com/blacktop/ipsw-skill",
      "defaultBranch": "main"
    },
    "metadata": {
      "stars": 30,
      "forks": 1,
      "language": null,
      "topics": [
        "apple",
        "claude-code",
        "claude-skills",
        "codex",
        "ipsw",
        "reverse-engineering",
        "skill",
        "vulnerability-research"
      ],
      "createdAt": "2025-12-24T17:59:06Z",
      "updatedAt": "2026-01-05T03:48:38Z",
      "pushedAt": "2026-01-04T19:16:12Z",
      "license": "MIT License"
    },
    "category": "tools",
    "tags": [
      "apple",
      "claude-code",
      "claude-skills",
      "codex",
      "ipsw",
      "reverse-engineering",
      "skill",
      "vulnerability-research",
      "analyzing",
      "firmware"
    ],
    "skillMd": {
      "raw": "---\nname: ipsw\ndescription: Apple firmware and binary reverse engineering with the ipsw CLI tool. Use when analyzing iOS/macOS binaries, disassembling functions in dyld_shared_cache, dumping Objective-C headers from private frameworks, downloading IPSWs or kernelcaches, extracting entitlements, analyzing Mach-O files, or researching Apple security. Triggers on requests involving Apple RE, iOS internals, kernel analysis, KEXT extraction, or vulnerability research on Apple platforms.\n---\n\n# IPSW - Apple Reverse Engineering Toolkit\n\n**Install:** `brew install blacktop/tap/ipsw`\n\n## Choose Your Workflow\n\n| Goal | Start Here |\n|------|------------|\n| Download/extract firmware | [Firmware Acquisition](#firmware-acquisition) |\n| Reverse engineer userspace | [Userspace RE](#userspace-re-dyld_shared_cache) |\n| Analyze kernel/KEXTs | [Kernel Analysis](#kernel-analysis) |\n| Research entitlements | [Entitlements](#entitlements) |\n| Dump private API headers | [Class Dump](#class-dump) |\n| Analyze standalone binary | [Mach-O Analysis](#mach-o-analysis) |\n\n---\n\n## Firmware Acquisition\n\n```bash\n# Download latest IPSW for device\nipsw download ipsw --device iPhone16,1 --latest\n\n# Download with automatic kernel/DSC extraction\nipsw download ipsw --device iPhone16,1 --latest --kernel --dyld\n\n# Extract components from local IPSW\nipsw extract --kernel iPhone16,1_18.0_Restore.ipsw\nipsw extract --dyld --dyld-arch arm64e iPhone16,1_18.0_Restore.ipsw\n\n# Remote extraction (no full download)\nipsw extract --kernel --remote <IPSW_URL>\n```\n\nSee [references/download.md](references/download.md) for device identifiers and advanced options.\n\n---\n\n## Userspace RE (dyld_shared_cache)\n\n**macOS DSC:** `/System/Volumes/Preboot/Cryptexes/OS/System/Library/dyld/dyld_shared_cache_arm64e`\n\n### Essential Commands\n\n| Command | Purpose |\n|---------|---------|\n| `dyld a2s <DSC> <ADDR>` | Address â†’ symbol (triage crash LR/PC) |\n| `dyld symaddr <DSC> <SYM> --image <DYLIB>` | Symbol â†’ address |\n| `dyld disass <DSC> --vaddr <ADDR>` | Disassemble at address |\n| `dyld disass <DSC> --symbol <SYM> --image <DYLIB>` | Disassemble by symbol |\n| `dyld xref <DSC> <ADDR> --all` | Find all references to address |\n| `dyld dump <DSC> <ADDR> --size 256` | Dump raw bytes at address |\n| `dyld str <DSC> \"pattern\" --image <DYLIB>` | Search strings |\n| `dyld objc --class <DSC> --image <DYLIB>` | List ObjC classes |\n| `dyld extract <DSC> <DYLIB> -o ./out/` | Extract dylib for external tools |\n\n### Common Workflow\n\n```bash\n# 1. Resolve address from crash/trace\nipsw dyld a2s $DSC 0x1bc39e1e0\n# â†’ -[SomeClass someMethod:] + 0x40\n\n# 2. Disassemble around that address\nipsw dyld disass $DSC --vaddr 0x1bc39e1e0\n\n# 3. Find who calls this function\nipsw dyld xref $DSC 0x1bc39e1a0 --all\n\n# 4. Extract string/data referenced in disassembly\nipsw dyld dump $DSC 0x1bc39e200 --size 64\n```\n\n**Tip:** Always use `--image <DYLIB>` - it's 10x+ faster.\n\nSee [references/dyld.md](references/dyld.md) for complete DSC commands.\n\n---\n\n## Kernel Analysis\n\n```bash\n# List all KEXTs\nipsw kernel kexts kernelcache.release.iPhone16,1\n\n# Extract specific KEXT\nipsw kernel extract kernelcache sandbox --output ./kexts/\n\n# Dump syscalls\nipsw kernel syscall kernelcache\n\n# Diff KEXTs between versions\nipsw kernel kexts --diff kernelcache_17.0 kernelcache_18.0\n```\n\nSee [references/kernel.md](references/kernel.md) for KEXT extraction and kernel analysis.\n\n---\n\n## Entitlements\n\n```bash\n# Single binary entitlements\nipsw macho info --ent /path/to/binary\n\n# Build searchable database from IPSW\nipsw ent --sqlite ent.db --ipsw iOS18.ipsw\n\n# Query database\nipsw ent --sqlite ent.db --key \"com.apple.private.security.no-sandbox\"\nipsw ent --sqlite ent.db --key \"platform-application\"\nipsw ent --sqlite ent.db --key \"com.apple.private.tcc.manager\"\n```\n\nSee [references/entitlements.md](references/entitlements.md) for common entitlements and query patterns.\n\n---\n\n## Class Dump\n\nDump Objective-C headers from binaries or dyld_shared_cache:\n\n```bash\n# Dump all headers from framework in DSC\nipsw class-dump $DSC SpringBoardServices --headers -o ./headers/\n\n# Dump specific class\nipsw class-dump $DSC Security --class SecKey\n\n# Filter by pattern\nipsw class-dump $DSC UIKit --class 'UIApplication.*' --headers -o ./headers/\n\n# Include runtime addresses (for hooking)\nipsw class-dump $DSC Security --re\n```\n\nSee [references/class-dump.md](references/class-dump.md) for filtering and output options.\n\n---\n\n## Mach-O Analysis\n\n```bash\n# Full binary info\nipsw macho info /path/to/binary\n\n# Disassemble function\nipsw macho disass /path/to/binary --symbol _main\n\n# Get entitlements and signature\nipsw macho info --ent /path/to/binary\nipsw macho info --sig /path/to/binary\n```\n\nSee [references/macho.md](references/macho.md) for complete Mach-O commands.\n\n---\n\n## Reference Files\n\n- [references/download.md](references/download.md) - Firmware download, device IDs, extraction\n- [references/dyld.md](references/dyld.md) - Complete DSC commands (a2s, xref, dump, str, extract)\n- [references/kernel.md](references/kernel.md) - Kernel and KEXT analysis\n- [references/entitlements.md](references/entitlements.md) - Entitlements database and queries\n- [references/class-dump.md](references/class-dump.md) - ObjC header dumping\n- [references/macho.md](references/macho.md) - Mach-O binary analysis\n\n## Tips\n\n1. **Symbol caching:** First `a2s`/`symaddr` creates `.a2s` cache - subsequent lookups are instant\n2. **Use --image flag:** Specifying dylib is 10x+ faster for DSC operations\n3. **JSON output:** Most commands support `--json` for scripting\n4. **Device IDs:** Use `ipsw device-list` to find device identifiers\n",
      "frontmatter": {
        "name": "ipsw",
        "description": "Apple firmware and binary reverse engineering with the ipsw CLI tool. Use when analyzing iOS/macOS binaries, disassembling functions in dyld_shared_cache, dumping Objective-C headers from private frameworks, downloading IPSWs or kernelcaches, extracting entitlements, analyzing Mach-O files, or researching Apple security. Triggers on requests involving Apple RE, iOS internals, kernel analysis, KEXT extraction, or vulnerability research on Apple platforms."
      },
      "content": "# IPSW - Apple Reverse Engineering Toolkit\n\n**Install:** `brew install blacktop/tap/ipsw`\n\n## Choose Your Workflow\n\n| Goal | Start Here |\n|------|------------|\n| Download/extract firmware | [Firmware Acquisition](#firmware-acquisition) |\n| Reverse engineer userspace | [Userspace RE](#userspace-re-dyld_shared_cache) |\n| Analyze kernel/KEXTs | [Kernel Analysis](#kernel-analysis) |\n| Research entitlements | [Entitlements](#entitlements) |\n| Dump private API headers | [Class Dump](#class-dump) |\n| Analyze standalone binary | [Mach-O Analysis](#mach-o-analysis) |\n\n---\n\n## Firmware Acquisition\n\n```bash\n# Download latest IPSW for device\nipsw download ipsw --device iPhone16,1 --latest\n\n# Download with automatic kernel/DSC extraction\nipsw download ipsw --device iPhone16,1 --latest --kernel --dyld\n\n# Extract components from local IPSW\nipsw extract --kernel iPhone16,1_18.0_Restore.ipsw\nipsw extract --dyld --dyld-arch arm64e iPhone16,1_18.0_Restore.ipsw\n\n# Remote extraction (no full download)\nipsw extract --kernel --remote <IPSW_URL>\n```\n\nSee [references/download.md](references/download.md) for device identifiers and advanced options.\n\n---\n\n## Userspace RE (dyld_shared_cache)\n\n**macOS DSC:** `/System/Volumes/Preboot/Cryptexes/OS/System/Library/dyld/dyld_shared_cache_arm64e`\n\n### Essential Commands\n\n| Command | Purpose |\n|---------|---------|\n| `dyld a2s <DSC> <ADDR>` | Address â†’ symbol (triage crash LR/PC) |\n| `dyld symaddr <DSC> <SYM> --image <DYLIB>` | Symbol â†’ address |\n| `dyld disass <DSC> --vaddr <ADDR>` | Disassemble at address |\n| `dyld disass <DSC> --symbol <SYM> --image <DYLIB>` | Disassemble by symbol |\n| `dyld xref <DSC> <ADDR> --all` | Find all references to address |\n| `dyld dump <DSC> <ADDR> --size 256` | Dump raw bytes at address |\n| `dyld str <DSC> \"pattern\" --image <DYLIB>` | Search strings |\n| `dyld objc --class <DSC> --image <DYLIB>` | List ObjC classes |\n| `dyld extract <DSC> <DYLIB> -o ./out/` | Extract dylib for external tools |\n\n### Common Workflow\n\n```bash\n# 1. Resolve address from crash/trace\nipsw dyld a2s $DSC 0x1bc39e1e0\n# â†’ -[SomeClass someMethod:] + 0x40\n\n# 2. Disassemble around that address\nipsw dyld disass $DSC --vaddr 0x1bc39e1e0\n\n# 3. Find who calls this function\nipsw dyld xref $DSC 0x1bc39e1a0 --all\n\n# 4. Extract string/data referenced in disassembly\nipsw dyld dump $DSC 0x1bc39e200 --size 64\n```\n\n**Tip:** Always use `--image <DYLIB>` - it's 10x+ faster.\n\nSee [references/dyld.md](references/dyld.md) for complete DSC commands.\n\n---\n\n## Kernel Analysis\n\n```bash\n# List all KEXTs\nipsw kernel kexts kernelcache.release.iPhone16,1\n\n# Extract specific KEXT\nipsw kernel extract kernelcache sandbox --output ./kexts/\n\n# Dump syscalls\nipsw kernel syscall kernelcache\n\n# Diff KEXTs between versions\nipsw kernel kexts --diff kernelcache_17.0 kernelcache_18.0\n```\n\nSee [references/kernel.md](references/kernel.md) for KEXT extraction and kernel analysis.\n\n---\n\n## Entitlements\n\n```bash\n# Single binary entitlements\nipsw macho info --ent /path/to/binary\n\n# Build searchable database from IPSW\nipsw ent --sqlite ent.db --ipsw iOS18.ipsw\n\n# Query database\nipsw ent --sqlite ent.db --key \"com.apple.private.security.no-sandbox\"\nipsw ent --sqlite ent.db --key \"platform-application\"\nipsw ent --sqlite ent.db --key \"com.apple.private.tcc.manager\"\n```\n\nSee [references/entitlements.md](references/entitlements.md) for common entitlements and query patterns.\n\n---\n\n## Class Dump\n\nDump Objective-C headers from binaries or dyld_shared_cache:\n\n```bash\n# Dump all headers from framework in DSC\nipsw class-dump $DSC SpringBoardServices --headers -o ./headers/\n\n# Dump specific class\nipsw class-dump $DSC Security --class SecKey\n\n# Filter by pattern\nipsw class-dump $DSC UIKit --class 'UIApplication.*' --headers -o ./headers/\n\n# Include runtime addresses (for hooking)\nipsw class-dump $DSC Security --re\n```\n\nSee [references/class-dump.md](references/class-dump.md) for filtering and output options.\n\n---\n\n## Mach-O Analysis\n\n```bash\n# Full binary info\nipsw macho info /path/to/binary\n\n# Disassemble function\nipsw macho disass /path/to/binary --symbol _main\n\n# Get entitlements and signature\nipsw macho info --ent /path/to/binary\nipsw macho info --sig /path/to/binary\n```\n\nSee [references/macho.md](references/macho.md) for complete Mach-O commands.\n\n---\n\n## Reference Files\n\n- [references/download.md](references/download.md) - Firmware download, device IDs, extraction\n- [references/dyld.md](references/dyld.md) - Complete DSC commands (a2s, xref, dump, str, extract)\n- [references/kernel.md](references/kernel.md) - Kernel and KEXT analysis\n- [references/entitlements.md](references/entitlements.md) - Entitlements database and queries\n- [references/class-dump.md](references/class-dump.md) - ObjC header dumping\n- [references/macho.md](references/macho.md) - Mach-O binary analysis\n\n## Tips\n\n1. **Symbol caching:** First `a2s`/`symaddr` creates `.a2s` cache - subsequent lookups are instant\n2. **Use --image flag:** Specifying dylib is 10x+ faster for DSC operations\n3. **JSON output:** Most commands support `--json` for scripting\n4. **Device IDs:** Use `ipsw device-list` to find device identifiers"
    },
    "marketplace": {
      "hasMarketplaceJson": false
    },
    "internal": {
      "syncedAt": "2026-01-08T00:37:42.119Z",
      "version": 1
    }
  },
  "jjmartres-reachy-mini-sdk-skill": {
    "id": "jjmartres-reachy-mini-sdk-skill",
    "name": "reachy-mini-sdk",
    "description": "Programming guide for Reachy Mini robot using Python SDK v1.2.6 and REST API. Use when controlling Reachy Mini robots, programming movements (head/antennas/body), accessing sensors (camera/microphone/IMU), recording motions, building AI applications, deploying to Hugging Face, or using the daemon REST API. Covers SDK patterns, coordinate systems, interpolation methods, app management, and OpenAPI client generation.",
    "repo": {
      "owner": "jjmartres",
      "name": "reachy-mini-sdk-skill",
      "fullName": "jjmartres/reachy-mini-sdk-skill",
      "url": "https://github.com/jjmartres/reachy-mini-sdk-skill",
      "defaultBranch": "main"
    },
    "metadata": {
      "stars": 3,
      "forks": 1,
      "language": "Python",
      "topics": [
        "agentskills",
        "claude-code",
        "claude-skills"
      ],
      "createdAt": "2026-01-04T08:49:31Z",
      "updatedAt": "2026-01-06T20:29:23Z",
      "pushedAt": "2026-01-04T11:05:43Z",
      "license": "MIT License"
    },
    "category": "development",
    "tags": [
      "agentskills",
      "claude-code",
      "claude-skills",
      "programming",
      "reachy",
      "mini",
      "using",
      "rest"
    ],
    "skillMd": {
      "raw": "---\nname: reachy-mini-sdk\ndescription: Programming guide for Reachy Mini robot using Python SDK v1.2.6 and REST API. Use when controlling Reachy Mini robots, programming movements (head/antennas/body), accessing sensors (camera/microphone/IMU), recording motions, building AI applications, deploying to Hugging Face, or using the daemon REST API. Covers SDK patterns, coordinate systems, interpolation methods, app management, and OpenAPI client generation.\nlicense: MIT (see LICENSE.txt)\n---\n\n# Reachy Mini SDK\n\nProgramming guide for Reachy Mini - an open-source desktop humanoid robot with 6-DOF head, expressive antennas, and AI integration.\n\n## Hardware\n\n- **Head**: 6-DOF Stewart platform (X,Y,Z + roll,pitch,yaw)\n- **Antennas**: 2 servos\n- **Body**: 360Â° yaw rotation\n- **Sensors**: Camera, microphone, IMU (Wireless only)\n\n**Daemon**: FastAPI on port 8000 (REST + WebSocket)\n\n## Quick Start\n\n### Installation\n\nSee `references/installation.md` for complete setup (uv/pip, platform-specific configs, permissions).\n\n### Basic Connection\n\n```python\nfrom reachy_mini import ReachyMini\n\n# Local\nwith ReachyMini() as mini:\n    pass\n\n# Remote (Wireless)\nwith ReachyMini(localhost_only=False) as mini:\n    pass\n```\n\n## Movement\n\nSee `references/movement_control.md` for complete guide (450+ lines with all patterns).\n\n### goto_target (Smooth Interpolation)\n\n```python\nfrom reachy_mini.utils import create_head_pose\nimport numpy as np\n\nmini.goto_target(\n    head=create_head_pose(z=10, roll=15, degrees=True, mm=True),\n    antennas=np.deg2rad([45, 45]),\n    body_yaw=np.deg2rad(30),\n    duration=2.0,\n    method=\"minjerk\"  # linear, ease, cartoon\n)\n```\n\n### set_target (Direct Control)\n\nFor high-frequency control (>30Hz):\n\n```python\nmini.set_target(\n    head=create_head_pose(z=5, mm=True),\n    antennas=[0.5, -0.5]\n)\n```\n\n### Coordinates\n\n- **Head**: Position in meters, orientation in radians\n- **Antennas**: Radians (Â±1.5)\n- **Body**: Radians (full 360Â°)\n\n## Sensors\n\nSee `references/sensors.md` for camera, audio, IMU details.\n\n```python\n# Camera (BGR numpy array)\nframe = mini.media.get_frame()\n\n# Audio (16kHz stereo)\nsamples = mini.media.get_audio_sample()\nmini.media.push_audio_sample(samples)  # Non-blocking\n\n# IMU (Wireless only)\nif hasattr(mini, 'imu'):\n    data = mini.imu.get_data()\n```\n\n## Motion Recording\n\n```python\nmini.start_recording()\n# Move robot\nmotion = mini.stop_recording()\nmotion.save(\"demo.pkl\")\n\n# Replay\nmotion.play()\n```\n\n## REST API\n\nSee `references/daemon_api.md` for all 25+ endpoints.\nSee `references/openapi_usage.md` for client generation.\n\n### Direct HTTP Control\n\n```python\nimport requests\n\n# Move via API\nrequests.post(\"http://localhost:8000/api/goto\", json={\n    \"head_pose\": {\"x\": 0, \"y\": 0, \"z\": 0.01, \"roll\": 0, \"pitch\": 0, \"yaw\": 0},\n    \"duration\": 2.0,\n    \"interpolation\": \"minjerk\"\n})\n\n# Get state\nstate = requests.get(\"http://localhost:8000/api/state/full-state\").json()\n```\n\n### Generate Clients\n\nSee `references/openapi_schema.json` for OpenAPI v3.1.0 spec.\n\n```bash\n# Python\nopenapi-generator-cli generate -i openapi_schema.json -g python -o client/\n\n# TypeScript\nopenapi-typescript openapi_schema.json -o types.ts\n\n# Go, Rust, Java, etc. (50+ languages supported)\n```\n\n## App Management\n\n```python\n# Install app\nrequests.post(\"http://localhost:8000/api/apps/install\", json={\n    \"name\": \"hand_tracker\",\n    \"source\": \"hf_space\",\n    \"space_id\": \"pollen-robotics/hand_tracker_v2\"\n})\n\n# Start app\nrequests.post(\"http://localhost:8000/api/apps/start-app/hand_tracker\")\n```\n\n## Motor Modes\n\n```python\n# Compliant (manual movement)\nrequests.post(\"http://localhost:8000/api/motors/set-mode\", \n              json={\"mode\": \"disabled\"})\n\n# Active control\nrequests.post(\"http://localhost:8000/api/motors/set-mode\", \n              json={\"mode\": \"enabled\"})\n\n# Gravity compensation\nrequests.post(\"http://localhost:8000/api/motors/set-mode\", \n              json={\"mode\": \"gravity_compensation\"})\n```\n\n## AI Integration\n\nSee `references/ai_integration.md` for LLM patterns, vision models, multimodal apps, and HuggingFace deployment.\n\n### Example: Object Detection\n\n```python\nfrom transformers import pipeline\n\ndetector = pipeline(\"object-detection\")\nframe = mini.media.get_frame()\nresults = detector(frame)\n\n# React to detections\nfor obj in results:\n    if obj['label'] == 'person':\n        mini.goto_target(antennas=np.deg2rad([45, 45]), duration=0.5)\n```\n\n## Common Patterns\n\n### Greeting Sequence\n\n```python\ndef greet():\n    mini.goto_target(head=create_head_pose(z=5, mm=True), duration=0.5)\n    mini.goto_target(antennas=np.deg2rad([45, 45]), duration=0.5)\n    for _ in range(2):\n        mini.goto_target(head=create_head_pose(pitch=-10, degrees=True), duration=0.3)\n        mini.goto_target(head=create_head_pose(pitch=10, degrees=True), duration=0.3)\n```\n\n### Scanning Motion\n\n```python\nfor angle in [-60, -30, 0, 30, 60]:\n    mini.goto_target(\n        body_yaw=np.deg2rad(angle),\n        head=create_head_pose(z=5, mm=True),\n        duration=1.0\n    )\n```\n\n## Reference Files\n\n- **installation.md** - Setup for Wireless/Lite/Simulation\n- **movement_control.md** - Complete movement guide (450+ lines)\n- **sensors.md** - Camera, microphone, IMU access\n- **ai_integration.md** - AI models, LLMs, apps, deployment\n- **daemon_api.md** - REST API reference (500+ lines, 25+ endpoints)\n- **openapi_schema.json** - OpenAPI v3.1.0 spec for client generation\n- **openapi_usage.md** - Using OpenAPI for automation\n- **api_quick_reference.md** - Quick reference card\n\n## Platform Notes\n\n- **Wireless**: Raspberry Pi, WiFi, includes IMU, use `localhost_only=False` from PC\n- **Lite**: USB connection, no IMU, use `localhost_only=True`\n- **Simulation**: MuJoCo-based, no hardware needed\n\n## Safety\n\n- SDK enforces limits automatically\n- Test in simulation first\n- Use appropriate durations (0.5-2.0s typically)\n- Always use context managers (`with ReachyMini()`)\n\n## Version\n\nSDK v1.2.6, OpenAPI v3.1.0\n\nSource: https://github.com/pollen-robotics/reachy_mini/tree/1.2.6\n",
      "frontmatter": {
        "name": "reachy-mini-sdk",
        "description": "Programming guide for Reachy Mini robot using Python SDK v1.2.6 and REST API. Use when controlling Reachy Mini robots, programming movements (head/antennas/body), accessing sensors (camera/microphone/IMU), recording motions, building AI applications, deploying to Hugging Face, or using the daemon REST API. Covers SDK patterns, coordinate systems, interpolation methods, app management, and OpenAPI client generation.",
        "license": "MIT (see LICENSE.txt)"
      },
      "content": "# Reachy Mini SDK\n\nProgramming guide for Reachy Mini - an open-source desktop humanoid robot with 6-DOF head, expressive antennas, and AI integration.\n\n## Hardware\n\n- **Head**: 6-DOF Stewart platform (X,Y,Z + roll,pitch,yaw)\n- **Antennas**: 2 servos\n- **Body**: 360Â° yaw rotation\n- **Sensors**: Camera, microphone, IMU (Wireless only)\n\n**Daemon**: FastAPI on port 8000 (REST + WebSocket)\n\n## Quick Start\n\n### Installation\n\nSee `references/installation.md` for complete setup (uv/pip, platform-specific configs, permissions).\n\n### Basic Connection\n\n```python\nfrom reachy_mini import ReachyMini\n\n# Local\nwith ReachyMini() as mini:\n    pass\n\n# Remote (Wireless)\nwith ReachyMini(localhost_only=False) as mini:\n    pass\n```\n\n## Movement\n\nSee `references/movement_control.md` for complete guide (450+ lines with all patterns).\n\n### goto_target (Smooth Interpolation)\n\n```python\nfrom reachy_mini.utils import create_head_pose\nimport numpy as np\n\nmini.goto_target(\n    head=create_head_pose(z=10, roll=15, degrees=True, mm=True),\n    antennas=np.deg2rad([45, 45]),\n    body_yaw=np.deg2rad(30),\n    duration=2.0,\n    method=\"minjerk\"  # linear, ease, cartoon\n)\n```\n\n### set_target (Direct Control)\n\nFor high-frequency control (>30Hz):\n\n```python\nmini.set_target(\n    head=create_head_pose(z=5, mm=True),\n    antennas=[0.5, -0.5]\n)\n```\n\n### Coordinates\n\n- **Head**: Position in meters, orientation in radians\n- **Antennas**: Radians (Â±1.5)\n- **Body**: Radians (full 360Â°)\n\n## Sensors\n\nSee `references/sensors.md` for camera, audio, IMU details.\n\n```python\n# Camera (BGR numpy array)\nframe = mini.media.get_frame()\n\n# Audio (16kHz stereo)\nsamples = mini.media.get_audio_sample()\nmini.media.push_audio_sample(samples)  # Non-blocking\n\n# IMU (Wireless only)\nif hasattr(mini, 'imu'):\n    data = mini.imu.get_data()\n```\n\n## Motion Recording\n\n```python\nmini.start_recording()\n# Move robot\nmotion = mini.stop_recording()\nmotion.save(\"demo.pkl\")\n\n# Replay\nmotion.play()\n```\n\n## REST API\n\nSee `references/daemon_api.md` for all 25+ endpoints.\nSee `references/openapi_usage.md` for client generation.\n\n### Direct HTTP Control\n\n```python\nimport requests\n\n# Move via API\nrequests.post(\"http://localhost:8000/api/goto\", json={\n    \"head_pose\": {\"x\": 0, \"y\": 0, \"z\": 0.01, \"roll\": 0, \"pitch\": 0, \"yaw\": 0},\n    \"duration\": 2.0,\n    \"interpolation\": \"minjerk\"\n})\n\n# Get state\nstate = requests.get(\"http://localhost:8000/api/state/full-state\").json()\n```\n\n### Generate Clients\n\nSee `references/openapi_schema.json` for OpenAPI v3.1.0 spec.\n\n```bash\n# Python\nopenapi-generator-cli generate -i openapi_schema.json -g python -o client/\n\n# TypeScript\nopenapi-typescript openapi_schema.json -o types.ts\n\n# Go, Rust, Java, etc. (50+ languages supported)\n```\n\n## App Management\n\n```python\n# Install app\nrequests.post(\"http://localhost:8000/api/apps/install\", json={\n    \"name\": \"hand_tracker\",\n    \"source\": \"hf_space\",\n    \"space_id\": \"pollen-robotics/hand_tracker_v2\"\n})\n\n# Start app\nrequests.post(\"http://localhost:8000/api/apps/start-app/hand_tracker\")\n```\n\n## Motor Modes\n\n```python\n# Compliant (manual movement)\nrequests.post(\"http://localhost:8000/api/motors/set-mode\", \n              json={\"mode\": \"disabled\"})\n\n# Active control\nrequests.post(\"http://localhost:8000/api/motors/set-mode\", \n              json={\"mode\": \"enabled\"})\n\n# Gravity compensation\nrequests.post(\"http://localhost:8000/api/motors/set-mode\", \n              json={\"mode\": \"gravity_compensation\"})\n```\n\n## AI Integration\n\nSee `references/ai_integration.md` for LLM patterns, vision models, multimodal apps, and HuggingFace deployment.\n\n### Example: Object Detection\n\n```python\nfrom transformers import pipeline\n\ndetector = pipeline(\"object-detection\")\nframe = mini.media.get_frame()\nresults = detector(frame)\n\n# React to detections\nfor obj in results:\n    if obj['label'] == 'person':\n        mini.goto_target(antennas=np.deg2rad([45, 45]), duration=0.5)\n```\n\n## Common Patterns\n\n### Greeting Sequence\n\n```python\ndef greet():\n    mini.goto_target(head=create_head_pose(z=5, mm=True), duration=0.5)\n    mini.goto_target(antennas=np.deg2rad([45, 45]), duration=0.5)\n    for _ in range(2):\n        mini.goto_target(head=create_head_pose(pitch=-10, degrees=True), duration=0.3)\n        mini.goto_target(head=create_head_pose(pitch=10, degrees=True), duration=0.3)\n```\n\n### Scanning Motion\n\n```python\nfor angle in [-60, -30, 0, 30, 60]:\n    mini.goto_target(\n        body_yaw=np.deg2rad(angle),\n        head=create_head_pose(z=5, mm=True),\n        duration=1.0\n    )\n```\n\n## Reference Files\n\n- **installation.md** - Setup for Wireless/Lite/Simulation\n- **movement_control.md** - Complete movement guide (450+ lines)\n- **sensors.md** - Camera, microphone, IMU access\n- **ai_integration.md** - AI models, LLMs, apps, deployment\n- **daemon_api.md** - REST API reference (500+ lines, 25+ endpoints)\n- **openapi_schema.json** - OpenAPI v3.1.0 spec for client generation\n- **openapi_usage.md** - Using OpenAPI for automation\n- **api_quick_reference.md** - Quick reference card\n\n## Platform Notes\n\n- **Wireless**: Raspberry Pi, WiFi, includes IMU, use `localhost_only=False` from PC\n- **Lite**: USB connection, no IMU, use `localhost_only=True`\n- **Simulation**: MuJoCo-based, no hardware needed\n\n## Safety\n\n- SDK enforces limits automatically\n- Test in simulation first\n- Use appropriate durations (0.5-2.0s typically)\n- Always use context managers (`with ReachyMini()`)\n\n## Version\n\nSDK v1.2.6, OpenAPI v3.1.0\n\nSource: https://github.com/pollen-robotics/reachy_mini/tree/1.2.6"
    },
    "marketplace": {
      "hasMarketplaceJson": false
    },
    "internal": {
      "syncedAt": "2026-01-08T00:38:53.188Z",
      "version": 1
    }
  },
  "texmeijin-video-to-gif-skill": {
    "id": "texmeijin-video-to-gif-skill",
    "name": "video-to-gif",
    "description": "Convert multiple video files (MOV/MP4) into a single merged GIF with customizable speed per segment.\nUse this skill when users want to:\n- Merge multiple videos into one GIF\n- Create demo GIFs from screen recordings\n- Combine video clips with different playback speeds\n- Convert videos to optimized GIFs with compression\nTriggers: \"create GIF from videos\", \"merge videos to GIF\", \"convert MOV to GIF\", \"combine videos into animated GIF\"\n",
    "repo": {
      "owner": "TeXmeijin",
      "name": "video-to-gif-skill",
      "fullName": "TeXmeijin/video-to-gif-skill",
      "url": "https://github.com/TeXmeijin/video-to-gif-skill",
      "defaultBranch": "main"
    },
    "metadata": {
      "stars": 0,
      "forks": 0,
      "language": "Shell",
      "topics": [
        "claude-code-skill",
        "claude-skills"
      ],
      "createdAt": "2026-01-04T08:58:02Z",
      "updatedAt": "2026-01-04T09:01:47Z",
      "pushedAt": "2026-01-04T09:00:58Z"
    },
    "category": "development",
    "tags": [
      "claude-code-skill",
      "claude-skills",
      "videos",
      "convert",
      "into",
      "with",
      "multiple"
    ],
    "skillMd": {
      "raw": "---\nname: video-to-gif\ndescription: |\n  Convert multiple video files (MOV/MP4) into a single merged GIF with customizable speed per segment.\n  Use this skill when users want to:\n  - Merge multiple videos into one GIF\n  - Create demo GIFs from screen recordings\n  - Combine video clips with different playback speeds\n  - Convert videos to optimized GIFs with compression\n  Triggers: \"create GIF from videos\", \"merge videos to GIF\", \"convert MOV to GIF\", \"combine videos into animated GIF\"\n---\n\n# Video to GIF Converter\n\nMerge multiple video files into a single optimized GIF with per-segment speed control.\n\n## Quick Start\n\n```bash\n.claude/skills/video-to-gif/scripts/merge_videos_to_gif.sh -o output.gif video1.mov:2 video2.mov:4.75 video3.mov:4.75\n```\n\n## Script Usage\n\n```\n.claude/skills/video-to-gif/scripts/merge_videos_to_gif.sh -o output.gif [options] video1:speed1 video2:speed2 ...\n```\n\n### Options\n\n| Option | Default | Description |\n|--------|---------|-------------|\n| `-o FILE` | (required) | Output GIF file path |\n| `-w WIDTH` | 800 | Output width in pixels |\n| `-h HEIGHT` | 338 | Output height in pixels |\n| `-f FPS` | 8 | Frames per second (lower = smaller file) |\n| `-c COLORS` | 128 | Max colors (64-256, lower = smaller file) |\n| `-l LOSSY` | 80 | Lossy compression 0-200 (higher = smaller file, more artifacts) |\n\n### Video Format\n\n`path/to/video.mov:speed_multiplier`\n\n- `1` = original speed\n- `2` = 2x faster (video plays in half the time)\n- `4.75` = 4.75x faster\n- `0.5` = half speed (slower playback)\n\n## Examples\n\n### Basic: Merge 3 videos with different speeds\n\nFirst video slower (2x), others fast (4.75x):\n\n```bash\n.claude/skills/video-to-gif/scripts/merge_videos_to_gif.sh -o demo.gif \\\n  ~/Desktop/intro.mov:2 \\\n  ~/Desktop/action.mov:4.75 \\\n  ~/Desktop/outro.mov:4.75\n```\n\n### Custom resolution and compression\n\nCreate a smaller GIF (640x360, 64 colors, high compression):\n\n```bash\n.claude/skills/video-to-gif/scripts/merge_videos_to_gif.sh -o small.gif -w 640 -h 360 -c 64 -l 120 \\\n  video1.mov:3 video2.mov:3\n```\n\n### Higher quality GIF\n\nMore colors and lower compression:\n\n```bash\n.claude/skills/video-to-gif/scripts/merge_videos_to_gif.sh -o hq.gif -f 10 -c 256 -l 40 \\\n  video.mov:2\n```\n\n## Dependencies\n\nRequired tools (install via Homebrew on macOS):\n\n```bash\nbrew install ffmpeg gifsicle\n```\n\n## Tips\n\n- **File size too large?** Reduce FPS (`-f 6`), colors (`-c 64`), or increase lossy (`-l 100`)\n- **Video looks choppy?** Increase FPS (`-f 12`) or reduce speed multiplier\n- **Black bars appearing?** Videos with different aspect ratios get padded to fit target dimensions\n- **First segment too fast?** Use a lower speed multiplier (e.g., `:1.5` instead of `:4`)\n",
      "frontmatter": {
        "name": "video-to-gif",
        "description": "Convert multiple video files (MOV/MP4) into a single merged GIF with customizable speed per segment.\nUse this skill when users want to:\n- Merge multiple videos into one GIF\n- Create demo GIFs from screen recordings\n- Combine video clips with different playback speeds\n- Convert videos to optimized GIFs with compression\nTriggers: \"create GIF from videos\", \"merge videos to GIF\", \"convert MOV to GIF\", \"combine videos into animated GIF\"\n"
      },
      "content": "# Video to GIF Converter\n\nMerge multiple video files into a single optimized GIF with per-segment speed control.\n\n## Quick Start\n\n```bash\n.claude/skills/video-to-gif/scripts/merge_videos_to_gif.sh -o output.gif video1.mov:2 video2.mov:4.75 video3.mov:4.75\n```\n\n## Script Usage\n\n```\n.claude/skills/video-to-gif/scripts/merge_videos_to_gif.sh -o output.gif [options] video1:speed1 video2:speed2 ...\n```\n\n### Options\n\n| Option | Default | Description |\n|--------|---------|-------------|\n| `-o FILE` | (required) | Output GIF file path |\n| `-w WIDTH` | 800 | Output width in pixels |\n| `-h HEIGHT` | 338 | Output height in pixels |\n| `-f FPS` | 8 | Frames per second (lower = smaller file) |\n| `-c COLORS` | 128 | Max colors (64-256, lower = smaller file) |\n| `-l LOSSY` | 80 | Lossy compression 0-200 (higher = smaller file, more artifacts) |\n\n### Video Format\n\n`path/to/video.mov:speed_multiplier`\n\n- `1` = original speed\n- `2` = 2x faster (video plays in half the time)\n- `4.75` = 4.75x faster\n- `0.5` = half speed (slower playback)\n\n## Examples\n\n### Basic: Merge 3 videos with different speeds\n\nFirst video slower (2x), others fast (4.75x):\n\n```bash\n.claude/skills/video-to-gif/scripts/merge_videos_to_gif.sh -o demo.gif \\\n  ~/Desktop/intro.mov:2 \\\n  ~/Desktop/action.mov:4.75 \\\n  ~/Desktop/outro.mov:4.75\n```\n\n### Custom resolution and compression\n\nCreate a smaller GIF (640x360, 64 colors, high compression):\n\n```bash\n.claude/skills/video-to-gif/scripts/merge_videos_to_gif.sh -o small.gif -w 640 -h 360 -c 64 -l 120 \\\n  video1.mov:3 video2.mov:3\n```\n\n### Higher quality GIF\n\nMore colors and lower compression:\n\n```bash\n.claude/skills/video-to-gif/scripts/merge_videos_to_gif.sh -o hq.gif -f 10 -c 256 -l 40 \\\n  video.mov:2\n```\n\n## Dependencies\n\nRequired tools (install via Homebrew on macOS):\n\n```bash\nbrew install ffmpeg gifsicle\n```\n\n## Tips\n\n- **File size too large?** Reduce FPS (`-f 6`), colors (`-c 64`), or increase lossy (`-l 100`)\n- **Video looks choppy?** Increase FPS (`-f 12`) or reduce speed multiplier\n- **Black bars appearing?** Videos with different aspect ratios get padded to fit target dimensions\n- **First segment too fast?** Use a lower speed multiplier (e.g., `:1.5` instead of `:4`)"
    },
    "marketplace": {
      "hasMarketplaceJson": false
    },
    "internal": {
      "syncedAt": "2026-01-08T00:39:12.182Z",
      "version": 1
    }
  },
  "finelagusaz-proofread-ja": {
    "id": "finelagusaz-proofread-ja",
    "name": "proofread-ja",
    "description": "æ—¥æœ¬èªžãƒ†ã‚­ã‚¹ãƒˆã®èª¤å­—è„±å­—ãƒã‚§ãƒƒã‚¯ã€è¡¨è¨˜æºã‚Œã®æ¤œå‡ºã¨ä¿®æ­£ã€‚å°èª¬ã€æŠ€è¡“æ–‡æ›¸ã€ãƒ–ãƒ­ã‚°è¨˜äº‹ãªã©ã§ä½¿ç”¨ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œèª¤å­—è„±å­—ã‚’ãƒã‚§ãƒƒã‚¯ã€ã€Œè¡¨è¨˜ã®æºã‚Œã‚’ç¢ºèªã€ã€Œæ ¡æ­£ã—ã¦ã€ãªã©ã¨ä¾é ¼ã—ãŸæ™‚ã€ã¾ãŸã¯æ–‡æ›¸ã®å“è³ªå‘ä¸ŠãŒå¿…è¦ãªæ™‚ã«ä½¿ç”¨ã€‚",
    "repo": {
      "owner": "finelagusaz",
      "name": "proofread-ja",
      "fullName": "finelagusaz/proofread-ja",
      "url": "https://github.com/finelagusaz/proofread-ja",
      "defaultBranch": "main"
    },
    "metadata": {
      "stars": 1,
      "forks": 0,
      "language": null,
      "topics": [
        "claude-code-skill",
        "claude-skills"
      ],
      "createdAt": "2025-11-13T00:39:53Z",
      "updatedAt": "2026-01-03T09:12:17Z",
      "pushedAt": "2026-01-03T03:53:59Z"
    },
    "category": "development",
    "tags": [
      "claude-code-skill",
      "claude-skills"
    ],
    "skillMd": {
      "raw": "---\nname: proofread-ja\ndescription: æ—¥æœ¬èªžãƒ†ã‚­ã‚¹ãƒˆã®èª¤å­—è„±å­—ãƒã‚§ãƒƒã‚¯ã€è¡¨è¨˜æºã‚Œã®æ¤œå‡ºã¨ä¿®æ­£ã€‚å°èª¬ã€æŠ€è¡“æ–‡æ›¸ã€ãƒ–ãƒ­ã‚°è¨˜äº‹ãªã©ã§ä½¿ç”¨ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œèª¤å­—è„±å­—ã‚’ãƒã‚§ãƒƒã‚¯ã€ã€Œè¡¨è¨˜ã®æºã‚Œã‚’ç¢ºèªã€ã€Œæ ¡æ­£ã—ã¦ã€ãªã©ã¨ä¾é ¼ã—ãŸæ™‚ã€ã¾ãŸã¯æ–‡æ›¸ã®å“è³ªå‘ä¸ŠãŒå¿…è¦ãªæ™‚ã«ä½¿ç”¨ã€‚\n---\n\n# æ—¥æœ¬èªžæ ¡æ­£ã‚¹ã‚­ãƒ«\n\n## ã‚¹ã‚³ãƒ¼ãƒ—ã¨åˆ¶é™\n\n### å‡¦ç†å¯èƒ½ãªæ–‡å­—æ•°\n\n| æ–‡å­—æ•°          | å‡¦ç†æ–¹é‡                                                                 |\n|-----------------|--------------------------------------------------------------------------|\n| ã€œ3,000å­—       | å…¨æ–‡ã‚’ä¸€æ‹¬ãƒã‚§ãƒƒã‚¯                                                       |\n| 3,000ã€œ10,000å­— | ã‚»ã‚¯ã‚·ãƒ§ãƒ³å˜ä½ã§é †æ¬¡ãƒã‚§ãƒƒã‚¯ã€æœ€å¾Œã«å…¨ä½“ã®è¡¨è¨˜æºã‚Œã‚’ç¢ºèª                 |\n| 10,000å­—ã€œ      | ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«åˆ†å‰²ã‚’ææ¡ˆã€é‡ç‚¹ç®‡æ‰€ã®æŒ‡å®šã€ã¾ãŸã¯ã€Œè¡¨è¨˜æºã‚Œã®ã¿å…¨æ–‡ãƒã‚§ãƒƒã‚¯ã€ |\n\n### å‡¦ç†ãƒ¢ãƒ¼ãƒ‰\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¾é ¼ã«å¿œã˜ã¦ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠžã™ã‚‹ã€‚\n\n| ãƒ¢ãƒ¼ãƒ‰       | ãƒˆãƒªã‚¬ãƒ¼ä¾‹                                         | å‡ºåŠ›                                  |\n|--------------|----------------------------------------------------|---------------------------------------|\n| è©³ç´°         | ã€Œã—ã£ã‹ã‚Šæ ¡æ­£ã—ã¦ã€ã€Œå…¨éƒ¨ãƒã‚§ãƒƒã‚¯ã€               | å…¨ã‚«ãƒ†ã‚´ãƒªã®æŒ‡æ‘˜ + ä¿®æ­£ç‰ˆãƒ†ã‚­ã‚¹ãƒˆ     |\n| æ¨™æº–         | ã€Œæ ¡æ­£ã—ã¦ã€ã€Œãƒã‚§ãƒƒã‚¯ã—ã¦ã€                       | ç¢ºä¿¡åº¦ï¼šé«˜ãƒ»ä¸­ã®æŒ‡æ‘˜ + ä¿®æ­£ç‰ˆãƒ†ã‚­ã‚¹ãƒˆ |\n| ç°¡æ˜“         | ã€Œè»½ããƒã‚§ãƒƒã‚¯ã€ã€Œã–ã£ã¨è¦‹ã¦ã€ã€Œæ˜Žã‚‰ã‹ãªèª¤å­—ã ã‘ã€ | ç¢ºä¿¡åº¦ï¼šé«˜ã®ã¿ã€ç®‡æ¡æ›¸ãã§å ±å‘Š        |\n| è¡¨è¨˜çµ±ä¸€ã®ã¿ | ã€Œè¡¨è¨˜æºã‚Œã ã‘ç¢ºèªã€                               | è¡¨è¨˜æºã‚Œã®ä¸€è¦§ã®ã¿                    |\n\n## ãƒã‚§ãƒƒã‚¯é …ç›®\n\n### 1. èª¤å­—è„±å­—ã®æ¤œå‡º\n\n- åŒéŸ³ç•°ç¾©èªžã®èª¤ç”¨ï¼ˆä¾‹ï¼šä»¥å¤–/æ„å¤–ã€ä½œã‚‹/é€ ã‚‹/å‰µã‚‹ï¼‰\n- ã‚¿ã‚¤ãƒï¼ˆã‚­ãƒ¼ãƒœãƒ¼ãƒ‰é…ç½®ã«ã‚ˆã‚‹èª¤å…¥åŠ›ï¼‰\n- é€ã‚Šä»®åã®èª¤ã‚Š\n- å¤‰æ›ãƒŸã‚¹\n\n### 2. è¡¨è¨˜ã®æºã‚Œãƒã‚§ãƒƒã‚¯\n\n- æ¼¢å­—/ã²ã‚‰ãŒãªè¡¨è¨˜ï¼ˆä¾‹ï¼šã€Œäº‹ã€ã¨ã€Œã“ã¨ã€ï¼‰\n- ã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜ï¼ˆä¾‹ï¼šã€Œã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã€ã¨ã€Œã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼ã€ï¼‰\n- è‹±æ•°å­—ã®å…¨è§’/åŠè§’\n- å¥èª­ç‚¹ã®ç¨®é¡žï¼ˆã€‚ã€ã¨ï¼Žï¼Œï¼‰\n- é•·éŸ³ç¬¦ã®æœ‰ç„¡ï¼ˆã‚µãƒ¼ãƒãƒ¼/ã‚µãƒ¼ãƒï¼‰\n\n### 3. æ–‡ä½“ã®ä¸€è²«æ€§\n\n- æ•¬ä½“ï¼ˆã§ã™ãƒ»ã¾ã™ï¼‰/å¸¸ä½“ï¼ˆã ãƒ»ã§ã‚ã‚‹ï¼‰ã®æ··åœ¨\n- ä¸€äººç§°ã®çµ±ä¸€\n- æŽ¥ç¶šè©žã®ä½¿ç”¨é »åº¦\n\n### 4. æ–‡æ³•ãƒ»èªžæ³•ã®èª¤ã‚Š\n\n- ã‚‰æŠœãè¨€è‘‰ï¼ˆè¦‹ã‚Œã‚‹â†’è¦‹ã‚‰ã‚Œã‚‹ï¼‰\n- ã•å…¥ã‚Œè¨€è‘‰ï¼ˆèª­ã¾ã•ã›ã¦â†’èª­ã¾ã›ã¦ï¼‰\n- é‡è¤‡è¡¨ç¾ï¼ˆé ­ç—›ãŒç—›ã„ï¼‰\n- åŠ©è©žã®èª¤ç”¨ãƒ»é‡è¤‡\n\n## ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼\n\n### 1. ãƒ†ã‚­ã‚¹ãƒˆã®åˆ†æž\n\næ–‡æ›¸ã®ç¨®é¡žã‚’åˆ¤å®šã—ã€é©åˆ‡ãªãƒã‚§ãƒƒã‚¯åŸºæº–ã‚’é¸æŠžã™ã‚‹ã€‚\n\n| æ–‡æ›¸ã‚¿ã‚¤ãƒ—     | åˆ¤å®šã®æ‰‹ãŒã‹ã‚Š               | ãƒã‚§ãƒƒã‚¯æ–¹é‡                                               |\n|----------------|------------------------------|------------------------------------------------------------|\n| å°èª¬ãƒ»ã‚¨ãƒƒã‚»ã‚¤ | ä¸€äººç§°èªžã‚Šã€æƒ…æ™¯æå†™ã€ä¼šè©±æ–‡ | ã²ã‚‰ãŒãªå¤šã‚è¨±å®¹ã€æ–‡ä½“ã®ä¸€è²«æ€§é‡è¦–ã€ä¼šè©±æ–‡å†…ã¯æ–¹è¨€ãƒ»å£èªžOK |\n| æŠ€è¡“æ–‡æ›¸       | ã‚³ãƒ¼ãƒ‰ã€APIã€æ‰‹é †èª¬æ˜Ž        | æ¼¢å­—å¤šã‚ã€ç”¨èªžã®çµ±ä¸€é‡è¦–ã€é•·éŸ³ç¬¦ã®çµ±ä¸€                     |\n| ãƒ–ãƒ­ã‚°ãƒ»è¨˜äº‹   | è¦‹å‡ºã—ã€èª­è€…ã¸ã®å‘¼ã³ã‹ã‘     | æ–‡ä½“ã®æ··åœ¨ã¯æ–‡è„ˆæ¬¡ç¬¬ã§è¨±å®¹                                 |\n| ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸   | æ•¬èªžã€å®›åã€ç½²å             | æ•¬èªžã®æ­£ç¢ºã•ã€äºŒé‡æ•¬èªžãƒã‚§ãƒƒã‚¯                             |\n\n### 2. è©³ç´°ãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œ\n\nä»¥ä¸‹ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¦ãƒã‚§ãƒƒã‚¯ã‚’è¡Œã†ï¼š\n\n1. **references/common-errors.md** - å…¸åž‹çš„ãªèª¤ã‚Šã®ãƒ‘ã‚¿ãƒ¼ãƒ³\n2. **references/consistency-rules.md** - è¡¨è¨˜çµ±ä¸€ã®åŸºæº–\n3. **references/custom-terms.md** - ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ç”¨èªžï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰\n\nåˆ¤æ–­ã«è¿·ã†å ´åˆã¯ **examples/boundary-cases.md** ã‚’å‚ç…§ã€‚\n\n### 3. çµæžœã®å ±å‘Š\n\n#### ç¢ºä¿¡åº¦ã®å®šç¾©\n\n| ç¢ºä¿¡åº¦ | åŸºæº–                                             | ä¾‹                                                 |\n|--------|--------------------------------------------------|----------------------------------------------------|\n| é«˜     | æ˜Žã‚‰ã‹ãªèª¤ã‚Šã€‚æ–‡è„ˆã«é–¢ã‚ã‚‰ãšä¿®æ­£ã™ã¹ã           | ã€Œä»¥å¤–ã¨ç°¡å˜ã€â†’ã€Œæ„å¤–ã¨ã€ã€ã€Œè¦‹ã‚Œã‚‹ã€â†’ã€Œè¦‹ã‚‰ã‚Œã‚‹ã€ |\n| ä¸­     | è¡¨è¨˜æºã‚Œã€ã¾ãŸã¯æ–‡æ›¸ã‚¿ã‚¤ãƒ—ã«ã‚ˆã£ã¦åˆ¤æ–­ãŒåˆ†ã‹ã‚Œã‚‹ | ã€Œã“ã¨ã€ã¨ã€Œäº‹ã€ã®æ··åœ¨ã€é•·éŸ³ç¬¦ã®ä¸çµ±ä¸€             |\n| ä½Ž     | æ„å›³çš„ãªå¯èƒ½æ€§ãŒã‚ã‚‹ã€ã¾ãŸã¯è¨±å®¹ã•ã‚Œã‚‹å ´åˆã‚‚ã‚ã‚‹ | ä¼šè©±æ–‡ä¸­ã®ã€Œã‚‰æŠœãã€ã€å£èªžçš„ãªã€Œå…¨ç„¶ã„ã„ã€         |\n\n#### å ±å‘Šãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆï¼ˆæ¨™æº–ãƒ¢ãƒ¼ãƒ‰ï¼‰\n\n```markdown\n## æ ¡æ­£çµæžœ\n\n### ä¿®æ­£ææ¡ˆï¼ˆç¢ºä¿¡åº¦ï¼šé«˜ï¼‰\n\n| ç®‡æ‰€    | ç¾åœ¨ã®è¡¨è¨˜ | ä¿®æ­£æ¡ˆ   | ç†ç”±                               |\n|---------|------------|----------|------------------------------------|\n| 2æ®µè½ç›® | ä»¥å¤–ã¨     | æ„å¤–ã¨   | åŒéŸ³ç•°ç¾©èªžï¼ˆã€Œæ€ã„ãŒã‘ãšã€ã®æ„å‘³ï¼‰ |\n| 5æ®µè½ç›® | è¦‹ã‚Œã‚‹     | è¦‹ã‚‰ã‚Œã‚‹ | ã‚‰æŠœãè¨€è‘‰                         |\n\n### è¡¨è¨˜æºã‚Œï¼ˆç¢ºä¿¡åº¦ï¼šä¸­ï¼‰\n\næ–‡æ›¸å†…ã§ä»¥ä¸‹ã®è¡¨è¨˜ãŒæ··åœ¨ã—ã¦ã„ã¾ã™ã€‚ã©ã¡ã‚‰ã‹ã«çµ±ä¸€ã—ã¦ãã ã•ã„ã€‚\n\n| è¡¨è¨˜A    | å‡ºç¾  | è¡¨è¨˜B  | å‡ºç¾  | æŽ¨å¥¨                           |\n|----------|-------|--------|-------|--------------------------------|\n| ã“ã¨     | 8ç®‡æ‰€ | äº‹     | 3ç®‡æ‰€ | ã€Œã“ã¨ã€ï¼ˆå½¢å¼åè©žã¯ã²ã‚‰ãŒãªï¼‰ |\n| ãƒ¦ãƒ¼ã‚¶ãƒ¼ | 5ç®‡æ‰€ | ãƒ¦ãƒ¼ã‚¶ | 2ç®‡æ‰€ | ã©ã¡ã‚‰ã§ã‚‚å¯ï¼ˆçµ±ä¸€ãŒå¿…è¦ï¼‰     |\n\n### è¦ç¢ºèªï¼ˆç¢ºä¿¡åº¦ï¼šä½Žï¼‰\n\n| ç®‡æ‰€   | è¡¨è¨˜           | ç¢ºèªäº‹é …                             |\n|--------|----------------|--------------------------------------|\n| ä¼šè©±æ–‡ | ã€Œå…¨ç„¶å¤§ä¸ˆå¤«ã€ | å£èªžè¡¨ç¾ã¨ã—ã¦æ„å›³çš„ã§ã‚ã‚Œã°å•é¡Œãªã— |\n\n---\n\n## ä¿®æ­£ç‰ˆ\n\nï¼ˆç¢ºä¿¡åº¦ï¼šé«˜ã®é …ç›®ã‚’åæ˜ ã€è¡¨è¨˜æºã‚Œã¯å¤šæ•°æ´¾ã«çµ±ä¸€ï¼‰\n\n[ä¿®æ­£å¾Œã®å…¨æ–‡ã‚’ã“ã“ã«å‡ºåŠ›]\n```\n\n#### å ±å‘Šãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆï¼ˆç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰ï¼‰\n\n```markdown\n## æ ¡æ­£çµæžœï¼ˆç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼‰\n\nä»¥ä¸‹ã®æ˜Žã‚‰ã‹ãªèª¤ã‚Šã‚’æ¤œå‡ºã—ã¾ã—ãŸï¼š\n\n- 2æ®µè½ç›®ã€Œä»¥å¤–ã¨ã€â†’ã€Œæ„å¤–ã¨ã€\n- 5æ®µè½ç›®ã€Œè¦‹ã‚Œã‚‹ã€â†’ã€Œè¦‹ã‚‰ã‚Œã‚‹ã€\n- 8æ®µè½ç›®ã€Œé ­ç—›ãŒç—›ã„ã€â†’ã€Œé ­ãŒç—›ã„ã€\n\nä¿®æ­£ç‰ˆãŒå¿…è¦ãªå ´åˆã¯ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚\n```\n\n### 4. ä¿®æ­£ç‰ˆã®æä¾›\n\n1. ç¢ºä¿¡åº¦ã€Œé«˜ã€ã®é …ç›®ã‚’åæ˜ \n2. è¡¨è¨˜æºã‚Œã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠžã—ãŸæ–¹é‡ã€ã¾ãŸã¯å¤šæ•°æ´¾ã«çµ±ä¸€\n3. ç¢ºä¿¡åº¦ã€Œä½Žã€ã®é …ç›®ã¯å…ƒã®ã¾ã¾ç¶­æŒï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡ç¤ºã—ãŸå ´åˆã®ã¿ä¿®æ­£ï¼‰\n\nä¿®æ­£ç®‡æ‰€ã‚’æ˜Žç¤ºã™ã‚‹å ´åˆã¯ `ã€åŽŸæ–‡ï¼šã€œã€‘` å½¢å¼ã§ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒ¡ãƒ³ãƒˆã‚’ä»˜ã‘ã‚‹ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¸Œæœ›ã—ãŸå ´åˆã®ã¿ï¼‰ã€‚\n\n## åˆ¤æ–­åŸºæº–\n\n### ä¿®æ­£ã™ã¹ãï¼ˆç¢ºä¿¡åº¦ï¼šé«˜ï¼‰\n\n- æ˜Žã‚‰ã‹ãªèª¤å­—è„±å­—ï¼ˆå¤‰æ›ãƒŸã‚¹ã€ã‚¿ã‚¤ãƒï¼‰\n- åŒéŸ³ç•°ç¾©èªžã®èª¤ç”¨ã§æ„å‘³ãŒé€šã‚‰ãªã„\n- æ–‡æ³•çš„ãªèª¤ã‚Šï¼ˆæ´»ç”¨å½¢ã®èª¤ã‚Šï¼‰\n- äºŒé‡æ•¬èªžï¼ˆãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ã®å ´åˆï¼‰\n- æ„å‘³ãŒå¤‰ã‚ã‚‹èª¤ã‚Š\n\n### ç¢ºèªãŒå¿…è¦ï¼ˆç¢ºä¿¡åº¦ï¼šä¸­ï¼‰\n\n- è¡¨è¨˜æºã‚Œï¼ˆã©ã¡ã‚‰ã‚‚æ­£ã—ã„å ´åˆï¼‰\n- æ–‡æ›¸ã‚¿ã‚¤ãƒ—ã«ã‚ˆã£ã¦åˆ¤æ–­ãŒåˆ†ã‹ã‚Œã‚‹ã‚‚ã®\n- æ¼¢å­—/ã²ã‚‰ãŒãªã®é¸æŠž\n\n### æŒ‡æ‘˜ã®ã¿ï¼ˆç¢ºä¿¡åº¦ï¼šä½Žï¼‰\n\n- ä¼šè©±æ–‡ãƒ»å°è©žå†…ã®å£èªžè¡¨ç¾\n- æ–‡ä½“ã®æ„å›³çš„ãªæ··åœ¨ã®å¯èƒ½æ€§\n- ä½œè€…ã®å€‹æ€§ã¨ã—ã¦è¨±å®¹ã•ã‚Œã‚‹è¡¨ç¾\n\n### ä¿®æ­£ã—ãªã„\n\n- å¼•ç”¨æ–‡ä¸­ã®è¡¨è¨˜ï¼ˆåŽŸæ–‡ãƒžãƒžï¼‰\n- å›ºæœ‰åè©žï¼ˆäººåã€ä½œå“åã€å•†å“åï¼‰\n- æ˜Žç¤ºçš„ã«ã€Œè¨±å®¹ã€ã¨è¨­å®šã•ã‚ŒãŸè¡¨ç¾ï¼ˆcustom-terms.mdï¼‰\n- å°èª¬ã®ç™»å ´äººç‰©ã®å£èª¿ãƒ»æ–¹è¨€\n\n## å„ªå…ˆé †ä½\n\nå¤§é‡ã®å•é¡ŒãŒã‚ã‚‹å ´åˆã®å ±å‘Šé †åºï¼š\n\n1. **ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«**: æ„å‘³ãŒå¤‰ã‚ã‚‹èª¤å­—ï¼ˆåŒéŸ³ç•°ç¾©èªžï¼‰\n2. **é‡è¦**: æ–‡æ³•ã‚¨ãƒ©ãƒ¼ï¼ˆã‚‰æŠœãã€ã•å…¥ã‚Œã€æ´»ç”¨å½¢ï¼‰\n3. **ä¸­ç¨‹åº¦**: è¡¨è¨˜æºã‚Œï¼ˆçµ±ä¸€ãŒå¿…è¦ãªç®‡æ‰€ï¼‰\n4. **è»½å¾®**: ã‚¹ã‚¿ã‚¤ãƒ«ã®å•é¡Œï¼ˆå†—é•·è¡¨ç¾ã€å¥èª­ç‚¹ï¼‰\n\næŒ‡æ‘˜ãŒ20ä»¶ã‚’è¶…ãˆã‚‹å ´åˆã¯ã€ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ»é‡è¦ã‚’å„ªå…ˆã—ã€è»½å¾®ãªå•é¡Œã¯ã€Œä»–ã«â—‹ä»¶ã®è»½å¾®ãªæŒ‡æ‘˜ãŒã‚ã‚Šã¾ã™ã€ã¨ã¾ã¨ã‚ã‚‹ã€‚\n\n## å‚ç…§ãƒ•ã‚¡ã‚¤ãƒ«\n\n| ãƒ•ã‚¡ã‚¤ãƒ«                        | å†…å®¹                                   |\n|---------------------------------|----------------------------------------|\n| references/common-errors.md     | ã‚ˆãã‚ã‚‹èª¤å­—è„±å­—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³é›†           |\n| references/consistency-rules.md | è¡¨è¨˜çµ±ä¸€ã®åˆ¤æ–­åŸºæº–ã¨ãƒ«ãƒ¼ãƒ«             |\n| references/custom-terms.md      | ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ç”¨èªžé›†ï¼ˆç·¨é›†å¯èƒ½ï¼‰       |\n| examples/boundary-cases.md      | åˆ¤æ–­ã®å¢ƒç•Œä¾‹ï¼ˆç›´ã™/ç¢ºèª/ç¶­æŒã®åˆ†å²ç‚¹ï¼‰ |\n| examples/output-sample.md       | å‡ºåŠ›å½¢å¼ã®å…·ä½“ä¾‹                       |\n",
      "frontmatter": {
        "name": "proofread-ja",
        "description": "æ—¥æœ¬èªžãƒ†ã‚­ã‚¹ãƒˆã®èª¤å­—è„±å­—ãƒã‚§ãƒƒã‚¯ã€è¡¨è¨˜æºã‚Œã®æ¤œå‡ºã¨ä¿®æ­£ã€‚å°èª¬ã€æŠ€è¡“æ–‡æ›¸ã€ãƒ–ãƒ­ã‚°è¨˜äº‹ãªã©ã§ä½¿ç”¨ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œèª¤å­—è„±å­—ã‚’ãƒã‚§ãƒƒã‚¯ã€ã€Œè¡¨è¨˜ã®æºã‚Œã‚’ç¢ºèªã€ã€Œæ ¡æ­£ã—ã¦ã€ãªã©ã¨ä¾é ¼ã—ãŸæ™‚ã€ã¾ãŸã¯æ–‡æ›¸ã®å“è³ªå‘ä¸ŠãŒå¿…è¦ãªæ™‚ã«ä½¿ç”¨ã€‚"
      },
      "content": "# æ—¥æœ¬èªžæ ¡æ­£ã‚¹ã‚­ãƒ«\n\n## ã‚¹ã‚³ãƒ¼ãƒ—ã¨åˆ¶é™\n\n### å‡¦ç†å¯èƒ½ãªæ–‡å­—æ•°\n\n| æ–‡å­—æ•°          | å‡¦ç†æ–¹é‡                                                                 |\n|-----------------|--------------------------------------------------------------------------|\n| ã€œ3,000å­—       | å…¨æ–‡ã‚’ä¸€æ‹¬ãƒã‚§ãƒƒã‚¯                                                       |\n| 3,000ã€œ10,000å­— | ã‚»ã‚¯ã‚·ãƒ§ãƒ³å˜ä½ã§é †æ¬¡ãƒã‚§ãƒƒã‚¯ã€æœ€å¾Œã«å…¨ä½“ã®è¡¨è¨˜æºã‚Œã‚’ç¢ºèª                 |\n| 10,000å­—ã€œ      | ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«åˆ†å‰²ã‚’ææ¡ˆã€é‡ç‚¹ç®‡æ‰€ã®æŒ‡å®šã€ã¾ãŸã¯ã€Œè¡¨è¨˜æºã‚Œã®ã¿å…¨æ–‡ãƒã‚§ãƒƒã‚¯ã€ |\n\n### å‡¦ç†ãƒ¢ãƒ¼ãƒ‰\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¾é ¼ã«å¿œã˜ã¦ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠžã™ã‚‹ã€‚\n\n| ãƒ¢ãƒ¼ãƒ‰       | ãƒˆãƒªã‚¬ãƒ¼ä¾‹                                         | å‡ºåŠ›                                  |\n|--------------|----------------------------------------------------|---------------------------------------|\n| è©³ç´°         | ã€Œã—ã£ã‹ã‚Šæ ¡æ­£ã—ã¦ã€ã€Œå…¨éƒ¨ãƒã‚§ãƒƒã‚¯ã€               | å…¨ã‚«ãƒ†ã‚´ãƒªã®æŒ‡æ‘˜ + ä¿®æ­£ç‰ˆãƒ†ã‚­ã‚¹ãƒˆ     |\n| æ¨™æº–         | ã€Œæ ¡æ­£ã—ã¦ã€ã€Œãƒã‚§ãƒƒã‚¯ã—ã¦ã€                       | ç¢ºä¿¡åº¦ï¼šé«˜ãƒ»ä¸­ã®æŒ‡æ‘˜ + ä¿®æ­£ç‰ˆãƒ†ã‚­ã‚¹ãƒˆ |\n| ç°¡æ˜“         | ã€Œè»½ããƒã‚§ãƒƒã‚¯ã€ã€Œã–ã£ã¨è¦‹ã¦ã€ã€Œæ˜Žã‚‰ã‹ãªèª¤å­—ã ã‘ã€ | ç¢ºä¿¡åº¦ï¼šé«˜ã®ã¿ã€ç®‡æ¡æ›¸ãã§å ±å‘Š        |\n| è¡¨è¨˜çµ±ä¸€ã®ã¿ | ã€Œè¡¨è¨˜æºã‚Œã ã‘ç¢ºèªã€                               | è¡¨è¨˜æºã‚Œã®ä¸€è¦§ã®ã¿                    |\n\n## ãƒã‚§ãƒƒã‚¯é …ç›®\n\n### 1. èª¤å­—è„±å­—ã®æ¤œå‡º\n\n- åŒéŸ³ç•°ç¾©èªžã®èª¤ç”¨ï¼ˆä¾‹ï¼šä»¥å¤–/æ„å¤–ã€ä½œã‚‹/é€ ã‚‹/å‰µã‚‹ï¼‰\n- ã‚¿ã‚¤ãƒï¼ˆã‚­ãƒ¼ãƒœãƒ¼ãƒ‰é…ç½®ã«ã‚ˆã‚‹èª¤å…¥åŠ›ï¼‰\n- é€ã‚Šä»®åã®èª¤ã‚Š\n- å¤‰æ›ãƒŸã‚¹\n\n### 2. è¡¨è¨˜ã®æºã‚Œãƒã‚§ãƒƒã‚¯\n\n- æ¼¢å­—/ã²ã‚‰ãŒãªè¡¨è¨˜ï¼ˆä¾‹ï¼šã€Œäº‹ã€ã¨ã€Œã“ã¨ã€ï¼‰\n- ã‚«ã‚¿ã‚«ãƒŠè¡¨è¨˜ï¼ˆä¾‹ï¼šã€Œã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã€ã¨ã€Œã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼ã€ï¼‰\n- è‹±æ•°å­—ã®å…¨è§’/åŠè§’\n- å¥èª­ç‚¹ã®ç¨®é¡žï¼ˆã€‚ã€ã¨ï¼Žï¼Œï¼‰\n- é•·éŸ³ç¬¦ã®æœ‰ç„¡ï¼ˆã‚µãƒ¼ãƒãƒ¼/ã‚µãƒ¼ãƒï¼‰\n\n### 3. æ–‡ä½“ã®ä¸€è²«æ€§\n\n- æ•¬ä½“ï¼ˆã§ã™ãƒ»ã¾ã™ï¼‰/å¸¸ä½“ï¼ˆã ãƒ»ã§ã‚ã‚‹ï¼‰ã®æ··åœ¨\n- ä¸€äººç§°ã®çµ±ä¸€\n- æŽ¥ç¶šè©žã®ä½¿ç”¨é »åº¦\n\n### 4. æ–‡æ³•ãƒ»èªžæ³•ã®èª¤ã‚Š\n\n- ã‚‰æŠœãè¨€è‘‰ï¼ˆè¦‹ã‚Œã‚‹â†’è¦‹ã‚‰ã‚Œã‚‹ï¼‰\n- ã•å…¥ã‚Œè¨€è‘‰ï¼ˆèª­ã¾ã•ã›ã¦â†’èª­ã¾ã›ã¦ï¼‰\n- é‡è¤‡è¡¨ç¾ï¼ˆé ­ç—›ãŒç—›ã„ï¼‰\n- åŠ©è©žã®èª¤ç”¨ãƒ»é‡è¤‡\n\n## ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼\n\n### 1. ãƒ†ã‚­ã‚¹ãƒˆã®åˆ†æž\n\næ–‡æ›¸ã®ç¨®é¡žã‚’åˆ¤å®šã—ã€é©åˆ‡ãªãƒã‚§ãƒƒã‚¯åŸºæº–ã‚’é¸æŠžã™ã‚‹ã€‚\n\n| æ–‡æ›¸ã‚¿ã‚¤ãƒ—     | åˆ¤å®šã®æ‰‹ãŒã‹ã‚Š               | ãƒã‚§ãƒƒã‚¯æ–¹é‡                                               |\n|----------------|------------------------------|------------------------------------------------------------|\n| å°èª¬ãƒ»ã‚¨ãƒƒã‚»ã‚¤ | ä¸€äººç§°èªžã‚Šã€æƒ…æ™¯æå†™ã€ä¼šè©±æ–‡ | ã²ã‚‰ãŒãªå¤šã‚è¨±å®¹ã€æ–‡ä½“ã®ä¸€è²«æ€§é‡è¦–ã€ä¼šè©±æ–‡å†…ã¯æ–¹è¨€ãƒ»å£èªžOK |\n| æŠ€è¡“æ–‡æ›¸       | ã‚³ãƒ¼ãƒ‰ã€APIã€æ‰‹é †èª¬æ˜Ž        | æ¼¢å­—å¤šã‚ã€ç”¨èªžã®çµ±ä¸€é‡è¦–ã€é•·éŸ³ç¬¦ã®çµ±ä¸€                     |\n| ãƒ–ãƒ­ã‚°ãƒ»è¨˜äº‹   | è¦‹å‡ºã—ã€èª­è€…ã¸ã®å‘¼ã³ã‹ã‘     | æ–‡ä½“ã®æ··åœ¨ã¯æ–‡è„ˆæ¬¡ç¬¬ã§è¨±å®¹                                 |\n| ãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸   | æ•¬èªžã€å®›åã€ç½²å             | æ•¬èªžã®æ­£ç¢ºã•ã€äºŒé‡æ•¬èªžãƒã‚§ãƒƒã‚¯                             |\n\n### 2. è©³ç´°ãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œ\n\nä»¥ä¸‹ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¦ãƒã‚§ãƒƒã‚¯ã‚’è¡Œã†ï¼š\n\n1. **references/common-errors.md** - å…¸åž‹çš„ãªèª¤ã‚Šã®ãƒ‘ã‚¿ãƒ¼ãƒ³\n2. **references/consistency-rules.md** - è¡¨è¨˜çµ±ä¸€ã®åŸºæº–\n3. **references/custom-terms.md** - ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ç”¨èªžï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰\n\nåˆ¤æ–­ã«è¿·ã†å ´åˆã¯ **examples/boundary-cases.md** ã‚’å‚ç…§ã€‚\n\n### 3. çµæžœã®å ±å‘Š\n\n#### ç¢ºä¿¡åº¦ã®å®šç¾©\n\n| ç¢ºä¿¡åº¦ | åŸºæº–                                             | ä¾‹                                                 |\n|--------|--------------------------------------------------|----------------------------------------------------|\n| é«˜     | æ˜Žã‚‰ã‹ãªèª¤ã‚Šã€‚æ–‡è„ˆã«é–¢ã‚ã‚‰ãšä¿®æ­£ã™ã¹ã           | ã€Œä»¥å¤–ã¨ç°¡å˜ã€â†’ã€Œæ„å¤–ã¨ã€ã€ã€Œè¦‹ã‚Œã‚‹ã€â†’ã€Œè¦‹ã‚‰ã‚Œã‚‹ã€ |\n| ä¸­     | è¡¨è¨˜æºã‚Œã€ã¾ãŸã¯æ–‡æ›¸ã‚¿ã‚¤ãƒ—ã«ã‚ˆã£ã¦åˆ¤æ–­ãŒåˆ†ã‹ã‚Œã‚‹ | ã€Œã“ã¨ã€ã¨ã€Œäº‹ã€ã®æ··åœ¨ã€é•·éŸ³ç¬¦ã®ä¸çµ±ä¸€             |\n| ä½Ž     | æ„å›³çš„ãªå¯èƒ½æ€§ãŒã‚ã‚‹ã€ã¾ãŸã¯è¨±å®¹ã•ã‚Œã‚‹å ´åˆã‚‚ã‚ã‚‹ | ä¼šè©±æ–‡ä¸­ã®ã€Œã‚‰æŠœãã€ã€å£èªžçš„ãªã€Œå…¨ç„¶ã„ã„ã€         |\n\n#### å ±å‘Šãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆï¼ˆæ¨™æº–ãƒ¢ãƒ¼ãƒ‰ï¼‰\n\n```markdown\n## æ ¡æ­£çµæžœ\n\n### ä¿®æ­£ææ¡ˆï¼ˆç¢ºä¿¡åº¦ï¼šé«˜ï¼‰\n\n| ç®‡æ‰€    | ç¾åœ¨ã®è¡¨è¨˜ | ä¿®æ­£æ¡ˆ   | ç†ç”±                               |\n|---------|------------|----------|------------------------------------|\n| 2æ®µè½ç›® | ä»¥å¤–ã¨     | æ„å¤–ã¨   | åŒéŸ³ç•°ç¾©èªžï¼ˆã€Œæ€ã„ãŒã‘ãšã€ã®æ„å‘³ï¼‰ |\n| 5æ®µè½ç›® | è¦‹ã‚Œã‚‹     | è¦‹ã‚‰ã‚Œã‚‹ | ã‚‰æŠœãè¨€è‘‰                         |\n\n### è¡¨è¨˜æºã‚Œï¼ˆç¢ºä¿¡åº¦ï¼šä¸­ï¼‰\n\næ–‡æ›¸å†…ã§ä»¥ä¸‹ã®è¡¨è¨˜ãŒæ··åœ¨ã—ã¦ã„ã¾ã™ã€‚ã©ã¡ã‚‰ã‹ã«çµ±ä¸€ã—ã¦ãã ã•ã„ã€‚\n\n| è¡¨è¨˜A    | å‡ºç¾  | è¡¨è¨˜B  | å‡ºç¾  | æŽ¨å¥¨                           |\n|----------|-------|--------|-------|--------------------------------|\n| ã“ã¨     | 8ç®‡æ‰€ | äº‹     | 3ç®‡æ‰€ | ã€Œã“ã¨ã€ï¼ˆå½¢å¼åè©žã¯ã²ã‚‰ãŒãªï¼‰ |\n| ãƒ¦ãƒ¼ã‚¶ãƒ¼ | 5ç®‡æ‰€ | ãƒ¦ãƒ¼ã‚¶ | 2ç®‡æ‰€ | ã©ã¡ã‚‰ã§ã‚‚å¯ï¼ˆçµ±ä¸€ãŒå¿…è¦ï¼‰     |\n\n### è¦ç¢ºèªï¼ˆç¢ºä¿¡åº¦ï¼šä½Žï¼‰\n\n| ç®‡æ‰€   | è¡¨è¨˜           | ç¢ºèªäº‹é …                             |\n|--------|----------------|--------------------------------------|\n| ä¼šè©±æ–‡ | ã€Œå…¨ç„¶å¤§ä¸ˆå¤«ã€ | å£èªžè¡¨ç¾ã¨ã—ã¦æ„å›³çš„ã§ã‚ã‚Œã°å•é¡Œãªã— |\n\n---\n\n## ä¿®æ­£ç‰ˆ\n\nï¼ˆç¢ºä¿¡åº¦ï¼šé«˜ã®é …ç›®ã‚’åæ˜ ã€è¡¨è¨˜æºã‚Œã¯å¤šæ•°æ´¾ã«çµ±ä¸€ï¼‰\n\n[ä¿®æ­£å¾Œã®å…¨æ–‡ã‚’ã“ã“ã«å‡ºåŠ›]\n```\n\n#### å ±å‘Šãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆï¼ˆç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰ï¼‰\n\n```markdown\n## æ ¡æ­£çµæžœï¼ˆç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼‰\n\nä»¥ä¸‹ã®æ˜Žã‚‰ã‹ãªèª¤ã‚Šã‚’æ¤œå‡ºã—ã¾ã—ãŸï¼š\n\n- 2æ®µè½ç›®ã€Œä»¥å¤–ã¨ã€â†’ã€Œæ„å¤–ã¨ã€\n- 5æ®µè½ç›®ã€Œè¦‹ã‚Œã‚‹ã€â†’ã€Œè¦‹ã‚‰ã‚Œã‚‹ã€\n- 8æ®µè½ç›®ã€Œé ­ç—›ãŒç—›ã„ã€â†’ã€Œé ­ãŒç—›ã„ã€\n\nä¿®æ­£ç‰ˆãŒå¿…è¦ãªå ´åˆã¯ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚\n```\n\n### 4. ä¿®æ­£ç‰ˆã®æä¾›\n\n1. ç¢ºä¿¡åº¦ã€Œé«˜ã€ã®é …ç›®ã‚’åæ˜ \n2. è¡¨è¨˜æºã‚Œã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒé¸æŠžã—ãŸæ–¹é‡ã€ã¾ãŸã¯å¤šæ•°æ´¾ã«çµ±ä¸€\n3. ç¢ºä¿¡åº¦ã€Œä½Žã€ã®é …ç›®ã¯å…ƒã®ã¾ã¾ç¶­æŒï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡ç¤ºã—ãŸå ´åˆã®ã¿ä¿®æ­£ï¼‰\n\nä¿®æ­£ç®‡æ‰€ã‚’æ˜Žç¤ºã™ã‚‹å ´åˆã¯ `ã€åŽŸæ–‡ï¼šã€œã€‘` å½¢å¼ã§ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒ¡ãƒ³ãƒˆã‚’ä»˜ã‘ã‚‹ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå¸Œæœ›ã—ãŸå ´åˆã®ã¿ï¼‰ã€‚\n\n## åˆ¤æ–­åŸºæº–\n\n### ä¿®æ­£ã™ã¹ãï¼ˆç¢ºä¿¡åº¦ï¼šé«˜ï¼‰\n\n- æ˜Žã‚‰ã‹ãªèª¤å­—è„±å­—ï¼ˆå¤‰æ›ãƒŸã‚¹ã€ã‚¿ã‚¤ãƒï¼‰\n- åŒéŸ³ç•°ç¾©èªžã®èª¤ç”¨ã§æ„å‘³ãŒé€šã‚‰ãªã„\n- æ–‡æ³•çš„ãªèª¤ã‚Šï¼ˆæ´»ç”¨å½¢ã®èª¤ã‚Šï¼‰\n- äºŒé‡æ•¬èªžï¼ˆãƒ“ã‚¸ãƒã‚¹æ–‡æ›¸ã®å ´åˆï¼‰\n- æ„å‘³ãŒå¤‰ã‚ã‚‹èª¤ã‚Š\n\n### ç¢ºèªãŒå¿…è¦ï¼ˆç¢ºä¿¡åº¦ï¼šä¸­ï¼‰\n\n- è¡¨è¨˜æºã‚Œï¼ˆã©ã¡ã‚‰ã‚‚æ­£ã—ã„å ´åˆï¼‰\n- æ–‡æ›¸ã‚¿ã‚¤ãƒ—ã«ã‚ˆã£ã¦åˆ¤æ–­ãŒåˆ†ã‹ã‚Œã‚‹ã‚‚ã®\n- æ¼¢å­—/ã²ã‚‰ãŒãªã®é¸æŠž\n\n### æŒ‡æ‘˜ã®ã¿ï¼ˆç¢ºä¿¡åº¦ï¼šä½Žï¼‰\n\n- ä¼šè©±æ–‡ãƒ»å°è©žå†…ã®å£èªžè¡¨ç¾\n- æ–‡ä½“ã®æ„å›³çš„ãªæ··åœ¨ã®å¯èƒ½æ€§\n- ä½œè€…ã®å€‹æ€§ã¨ã—ã¦è¨±å®¹ã•ã‚Œã‚‹è¡¨ç¾\n\n### ä¿®æ­£ã—ãªã„\n\n- å¼•ç”¨æ–‡ä¸­ã®è¡¨è¨˜ï¼ˆåŽŸæ–‡ãƒžãƒžï¼‰\n- å›ºæœ‰åè©žï¼ˆäººåã€ä½œå“åã€å•†å“åï¼‰\n- æ˜Žç¤ºçš„ã«ã€Œè¨±å®¹ã€ã¨è¨­å®šã•ã‚ŒãŸè¡¨ç¾ï¼ˆcustom-terms.mdï¼‰\n- å°èª¬ã®ç™»å ´äººç‰©ã®å£èª¿ãƒ»æ–¹è¨€\n\n## å„ªå…ˆé †ä½\n\nå¤§é‡ã®å•é¡ŒãŒã‚ã‚‹å ´åˆã®å ±å‘Šé †åºï¼š\n\n1. **ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«**: æ„å‘³ãŒå¤‰ã‚ã‚‹èª¤å­—ï¼ˆåŒéŸ³ç•°ç¾©èªžï¼‰\n2. **é‡è¦**: æ–‡æ³•ã‚¨ãƒ©ãƒ¼ï¼ˆã‚‰æŠœãã€ã•å…¥ã‚Œã€æ´»ç”¨å½¢ï¼‰\n3. **ä¸­ç¨‹åº¦**: è¡¨è¨˜æºã‚Œï¼ˆçµ±ä¸€ãŒå¿…è¦ãªç®‡æ‰€ï¼‰\n4. **è»½å¾®**: ã‚¹ã‚¿ã‚¤ãƒ«ã®å•é¡Œï¼ˆå†—é•·è¡¨ç¾ã€å¥èª­ç‚¹ï¼‰\n\næŒ‡æ‘˜ãŒ20ä»¶ã‚’è¶…ãˆã‚‹å ´åˆã¯ã€ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ»é‡è¦ã‚’å„ªå…ˆã—ã€è»½å¾®ãªå•é¡Œã¯ã€Œä»–ã«â—‹ä»¶ã®è»½å¾®ãªæŒ‡æ‘˜ãŒã‚ã‚Šã¾ã™ã€ã¨ã¾ã¨ã‚ã‚‹ã€‚\n\n## å‚ç…§ãƒ•ã‚¡ã‚¤ãƒ«\n\n| ãƒ•ã‚¡ã‚¤ãƒ«                        | å†…å®¹                                   |\n|---------------------------------|----------------------------------------|\n| references/common-errors.md     | ã‚ˆãã‚ã‚‹èª¤å­—è„±å­—ã®ãƒ‘ã‚¿ãƒ¼ãƒ³é›†           |\n| references/consistency-rules.md | è¡¨è¨˜çµ±ä¸€ã®åˆ¤æ–­åŸºæº–ã¨ãƒ«ãƒ¼ãƒ«             |\n| references/custom-terms.md      | ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ç”¨èªžé›†ï¼ˆç·¨é›†å¯èƒ½ï¼‰       |\n| examples/boundary-cases.md      | åˆ¤æ–­ã®å¢ƒç•Œä¾‹ï¼ˆç›´ã™/ç¢ºèª/ç¶­æŒã®åˆ†å²ç‚¹ï¼‰ |\n| examples/output-sample.md       | å‡ºåŠ›å½¢å¼ã®å…·ä½“ä¾‹                       |"
    },
    "marketplace": {
      "hasMarketplaceJson": false
    },
    "internal": {
      "syncedAt": "2026-01-08T00:41:28.041Z",
      "version": 1
    }
  },
  "abra5umente-radarr-skill": {
    "id": "abra5umente-radarr-skill",
    "name": "radarr",
    "description": "Manage movies via Radarr - search, add, monitor downloads, check wanted list. Use when user asks about movies to download, checking download queue, adding films to library, or managing their Radarr instance. Triggers on mentions of Radarr, movie downloads, adding movies, download queue, wanted movies.",
    "repo": {
      "owner": "abra5umente",
      "name": "radarr-skill",
      "fullName": "abra5umente/radarr-skill",
      "url": "https://github.com/abra5umente/radarr-skill",
      "defaultBranch": "main"
    },
    "metadata": {
      "stars": 0,
      "forks": 0,
      "language": "Python",
      "topics": [
        "ai",
        "claude",
        "claude-skills",
        "claude-skills-library",
        "homelab",
        "radarr"
      ],
      "createdAt": "2026-01-02T05:16:20Z",
      "updatedAt": "2026-01-02T05:30:14Z",
      "pushedAt": "2026-01-02T05:30:11Z",
      "license": "MIT License"
    },
    "category": "data-ai",
    "tags": [
      "ai",
      "claude",
      "claude-skills",
      "claude-skills-library",
      "homelab",
      "radarr",
      "movies",
      "download",
      "downloads",
      "wanted"
    ],
    "skillMd": {
      "raw": "---\nname: radarr\ndescription: Manage movies via Radarr - search, add, monitor downloads, check wanted list. Use when user asks about movies to download, checking download queue, adding films to library, or managing their Radarr instance. Triggers on mentions of Radarr, movie downloads, adding movies, download queue, wanted movies.\n---\n\n# Radarr Skill\n\nManage user's Radarr movie library via proxy. Large results save to disk (metadata only returned) to preserve context.\n\n## Scripts\n\nAll at `/mnt/skills/user/radarr/scripts/`\n\n### radarr.py\n\nMain interface for all Radarr operations.\n\n**Large results (movies, releases, queue, wanted) return metadata only. Full data saved to file.**\n\n```bash\n# Search for movies (returns full results - typically small)\npython3 radarr.py search \"The Matrix\" 1999\npython3 radarr.py search \"Interstellar\"\n\n# List library (returns count + path only)\npython3 radarr.py movies                    # All movies\npython3 radarr.py movies true               # Monitored only\n\n# Then grep the saved file to find specific movies\ngrep -i \"hotel\" /home/claude/radarr/movies_*.json\n\n# Get movie details (returns full result)\npython3 radarr.py movie 123\n\n# Add movie by TMDB ID (get ID from search results)\npython3 radarr.py add 603                   # The Matrix\n\n# Search for releases (returns count + path only)\npython3 radarr.py releases 123\n# Then grep for quality/size\ngrep -i \"1080p\\|bluray\" /home/claude/radarr/releases_*.json\n\n# Download a release\npython3 radarr.py download \"release-guid\" 123\n\n# Check download queue (returns count + path only)\npython3 radarr.py queue\ngrep -i \"title\" /home/claude/radarr/queue_*.json\n\n# Get wanted/missing movies (returns count + path only)\npython3 radarr.py wanted\n\n# System status (returns full result)\npython3 radarr.py status\n```\n\n### storage.py\n\nManage cached results.\n\n```bash\npython3 storage.py list              # Show all cached results\npython3 storage.py get <filename>    # Load specific result\npython3 storage.py clear             # Clear cache\n```\n\n## Cache Location\n\n```\n/home/claude/radarr/\nâ”œâ”€â”€ search_*.json\nâ”œâ”€â”€ movies_*.json\nâ”œâ”€â”€ releases_*.json\nâ”œâ”€â”€ queue_*.json\nâ””â”€â”€ manifest.json\n```\n\n## Typical Workflows\n\n### Check if a movie is in library\n```bash\n# 1. Fetch library (saves to file, returns count only)\npython3 radarr.py movies\n# 2. Grep the file for the movie\ngrep -i \"hotel transylvania\" /home/claude/radarr/movies_*.json\n```\n\n### Find and add a movie\n```bash\n# 1. Search (returns full results)\npython3 radarr.py search \"Dune\" 2021\n# 2. Note the tmdb_id from results\n# 3. Add it\npython3 radarr.py add 438631\n```\n\n### Check what's downloading\n```bash\npython3 radarr.py queue\n# If items exist, grep for details\ngrep -i \"title\\|progress\" /home/claude/radarr/queue_*.json\n```\n\n### Find missing movies\n```bash\npython3 radarr.py wanted\ngrep -i \"title\" /home/claude/radarr/wanted_*.json\n```\n\n### Manually grab a release\n```bash\n# 1. Get movie ID from library\npython3 radarr.py movies\ngrep -i \"movie name\" /home/claude/radarr/movies_*.json | grep '\"id\"'\n# 2. Search releases\npython3 radarr.py releases 123\n# 3. Find a good release\ngrep -i \"1080p\" /home/claude/radarr/releases_*.json | head -20\n# 4. Download preferred release (get guid from grep output)\npython3 radarr.py download \"release-guid-here\" 123\n```\n\n## Notes\n\n- **Large results (movies, releases, queue, wanted) return metadata only** - full data in file\n- **Small results (search, status, movie details, add) return full data**\n- Grep the saved files directly, don't pipe stdout\n- TMDB IDs are used for adding movies (shown in search results)\n- Movie IDs (internal Radarr IDs) are used for releases/details\n- Quality profiles and root folders use Radarr defaults\n- Files are timestamped, use `*.json` glob to find latest\n",
      "frontmatter": {
        "name": "radarr",
        "description": "Manage movies via Radarr - search, add, monitor downloads, check wanted list. Use when user asks about movies to download, checking download queue, adding films to library, or managing their Radarr instance. Triggers on mentions of Radarr, movie downloads, adding movies, download queue, wanted movies."
      },
      "content": "# Radarr Skill\n\nManage user's Radarr movie library via proxy. Large results save to disk (metadata only returned) to preserve context.\n\n## Scripts\n\nAll at `/mnt/skills/user/radarr/scripts/`\n\n### radarr.py\n\nMain interface for all Radarr operations.\n\n**Large results (movies, releases, queue, wanted) return metadata only. Full data saved to file.**\n\n```bash\n# Search for movies (returns full results - typically small)\npython3 radarr.py search \"The Matrix\" 1999\npython3 radarr.py search \"Interstellar\"\n\n# List library (returns count + path only)\npython3 radarr.py movies                    # All movies\npython3 radarr.py movies true               # Monitored only\n\n# Then grep the saved file to find specific movies\ngrep -i \"hotel\" /home/claude/radarr/movies_*.json\n\n# Get movie details (returns full result)\npython3 radarr.py movie 123\n\n# Add movie by TMDB ID (get ID from search results)\npython3 radarr.py add 603                   # The Matrix\n\n# Search for releases (returns count + path only)\npython3 radarr.py releases 123\n# Then grep for quality/size\ngrep -i \"1080p\\|bluray\" /home/claude/radarr/releases_*.json\n\n# Download a release\npython3 radarr.py download \"release-guid\" 123\n\n# Check download queue (returns count + path only)\npython3 radarr.py queue\ngrep -i \"title\" /home/claude/radarr/queue_*.json\n\n# Get wanted/missing movies (returns count + path only)\npython3 radarr.py wanted\n\n# System status (returns full result)\npython3 radarr.py status\n```\n\n### storage.py\n\nManage cached results.\n\n```bash\npython3 storage.py list              # Show all cached results\npython3 storage.py get <filename>    # Load specific result\npython3 storage.py clear             # Clear cache\n```\n\n## Cache Location\n\n```\n/home/claude/radarr/\nâ”œâ”€â”€ search_*.json\nâ”œâ”€â”€ movies_*.json\nâ”œâ”€â”€ releases_*.json\nâ”œâ”€â”€ queue_*.json\nâ””â”€â”€ manifest.json\n```\n\n## Typical Workflows\n\n### Check if a movie is in library\n```bash\n# 1. Fetch library (saves to file, returns count only)\npython3 radarr.py movies\n# 2. Grep the file for the movie\ngrep -i \"hotel transylvania\" /home/claude/radarr/movies_*.json\n```\n\n### Find and add a movie\n```bash\n# 1. Search (returns full results)\npython3 radarr.py search \"Dune\" 2021\n# 2. Note the tmdb_id from results\n# 3. Add it\npython3 radarr.py add 438631\n```\n\n### Check what's downloading\n```bash\npython3 radarr.py queue\n# If items exist, grep for details\ngrep -i \"title\\|progress\" /home/claude/radarr/queue_*.json\n```\n\n### Find missing movies\n```bash\npython3 radarr.py wanted\ngrep -i \"title\" /home/claude/radarr/wanted_*.json\n```\n\n### Manually grab a release\n```bash\n# 1. Get movie ID from library\npython3 radarr.py movies\ngrep -i \"movie name\" /home/claude/radarr/movies_*.json | grep '\"id\"'\n# 2. Search releases\npython3 radarr.py releases 123\n# 3. Find a good release\ngrep -i \"1080p\" /home/claude/radarr/releases_*.json | head -20\n# 4. Download preferred release (get guid from grep output)\npython3 radarr.py download \"release-guid-here\" 123\n```\n\n## Notes\n\n- **Large results (movies, releases, queue, wanted) return metadata only** - full data in file\n- **Small results (search, status, movie details, add) return full data**\n- Grep the saved files directly, don't pipe stdout\n- TMDB IDs are used for adding movies (shown in search results)\n- Movie IDs (internal Radarr IDs) are used for releases/details\n- Quality profiles and root folders use Radarr defaults\n- Files are timestamped, use `*.json` glob to find latest"
    },
    "marketplace": {
      "hasMarketplaceJson": false
    },
    "internal": {
      "syncedAt": "2026-01-08T00:41:42.987Z",
      "version": 1
    }
  }
}